{
  "hash": "6092b977fa08d56c3b3829ad0e37dad6",
  "result": {
    "markdown": "---\ntitle: Modelle mit Nutzungsintensität Fallstudie WPZ (fakultativ)\nauthor: \n  - B.Sigrist\ndate: 18. November 2019\nformat: pdf \n---\n\n\n\n\n## Neue packages die wir fuer die Modelle und die Diagnostics brauchen\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# neue Packages: DHARMa, car, MASS, ROCR, sjPlot, sjstats, rms, ggeffects,\n# cowplot\n\nipak <- function(pkg) {\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg))\n        install.packages(new.pkg, repos = \"http://cran.us.r-project.org\", dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n\npackages <- c(\"lme4\", \"bbmle\", \"MuMIn\", \"tidyverse\", \"DHARMa\", \"car\", \"MASS\", \"ROCR\",\n    \"sjPlot\", \"rms\", \"ggeffects\", \"sjstats\", \"cowplot\", \"glmmTMB\", \"performance\",\n    \"kableExtra\")\n\nipak(packages)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod_day <- read_delim(\"data/Datensatz_Habitatnutzung_Modelle_20191101.csv\", delim = \";\") %>%\n    filter(time_of_day == \"day\") %>%\n    mutate(slope_scaled = scale(slope), us_scaled = scale(us), os_scaled = scale(os),\n        forest_prop_scaled = scale(forest_prop), dist_road_scaled = scale(dist_road_all),\n        dist_road_only_scaled = scale(dist_road_only), dist_build_scaled = scale(dist_build),\n        id = as.factor(id))\n```\n:::\n\n\n## ursprüngliche Funktion und Modelformel\n\n\n::: {.cell ridy='true'}\n\n```{.r .cell-code}\n# glmer(formula, data = , family = binomial)\n\n# 1) formula: \n# Abhaengige Variable ~ Erklaerende Variable + Random Factor \n# In unseren Modellen kontrollieren wir fuer individuelle Unterschiede bei den Rehen \n# indem wir einen Random Factor definieren => (1 | id) \n\n# 2) data: \n# euer Datensatz\n\n# 3) family: \n# binomial\n\n# Verteilung der abhängigen Variable bei der Nutzungsintensität aus?\n\nggplot(DF_mod_day, aes(nmb)) + geom_histogram()\n```\n:::\n\n\n## Hinsichtlich der Nutzungsintensität müssen wir die Formel erweitern:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Erweiterung um einen sog. Offset-Term, der hier gebraucht wird, um für die\n# Anzahl der GPS Lokalisationen (in der Spalte GPStot aufgeführt) zu korrigeren\n# (eigentlich eine Skalierung der abhängigen Variable um die relative\n# Nutzungsintensität zu modellieren)\n\nf_count <- nmb ~ slope_scaled + dist_road_scaled + forest_prop_scaled + os_scaled +\n    us_scaled + dist_build_scaled + offset(log(GPStot)) + (1 | id)\n\n### Für die Nutzungsintensität brauchen wir ein neues package (glmmTMB) um das\n### GLMM fitten zu können. glmer kann leider mit der negativ binomial -\n### Verteilung nicht in jedem Fall umgehen.\n\nm <- glmmTMB(f_count, data = DF_mod_day, family = glmmTMB::nbinom2())\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n:::\n\n\n## Model testing for over/underdispersion, zeroinflation and spatial autocorrelation following the DHARMa package.\n## unbedingt die Vignette des DHARMa-Package konsultieren: https://cran.r-project.org/web/packages/DHARMa/vignettes/DHARMa.html\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf_count <- nmb ~ slope_scaled + dist_road_scaled + forest_prop_scaled + os_scaled +\n    us_scaled + offset(log(GPStot)) + (1 | id)\n\n### Für die Nutzungsintensität brauchen wir ein neues package (glmmTMB) um das\n### GLMM fitten zu können. glmer kann leider mit der negativ binomial -\n### Verteilung nicht in jedem Fall umgehen.\n\nm_day_count <- glmmTMB(f_count, data = DF_mod_day, family = glmmTMB::nbinom2())\n\nsummary(m_day_count)\n\ntab_model(m_day_count, transform = NULL, show.se = T)\n\n# Residuals werden ueber eine Simulation auf eine Standard-Skala transformiert\n# und kaennen anschliessend getestet werden. Dabei kann die Anzahl Simulationen\n# eingestellt werden (dauert je nach dem sehr lange)\n\nsimulationOutput <- simulateResiduals(fittedModel = m_day_count, n = 10000)\n\n# plotting and testing scaled residuals\n\nplot(simulationOutput)\n\ntestResiduals(simulationOutput)\n\n# The most common concern for GLMMs is overdispersion, underdispersion and\n# zero-inflation.\n\n# separate test for dispersion\n\ntestDispersion(simulationOutput)\n\n# test for Zeroinflation\n\ntestZeroInflation(simulationOutput)\n\n# test for spatial Autocorrelation\n\ndM = as.matrix(dist(cbind(DF_mod_day$x, DF_mod_day$y)))\n\ntestSpatialAutocorrelation(simulationOutput, distMat = dM, plot = F)\n\n# Testen auf Multicollinearitaet (dh zu starke Korrelationen im finalen Modell,\n# zB falls auf Grund der oekologsichen Plausibilitaet stark korrelierte\n# Variablen im Modell)\n#--> funktioniert bei glmmTMB Modellen mit dieser Funktion aus dem performace package:\n\ncheck_collinearity(m_day_count)\n```\n:::\n\n\n## AUC funktioniert nicht bei nicht-binären abhängigen Variablen, daher müssen wir eine andere Möglichkeit finden um den Goodness-of-fit der Modelle abzuschätzen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Zitat B.Bokler 2013: 'GLMMs are still part of the statistical frontier, and\n# not all of the answers about how to use them are known (even by experts)'\n\nr2(m_day_count)\n```\n:::\n\n\n## Plots der vorhergesagten relativen Nutzungsintensität funktionieren nach dem selben Prinzip das wir bereits kennen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# graphische Darstellung der gesamten Modellresultate\n\nplot_model(m_day_count, transform = NULL, show.values = TRUE, value.offset = 0.3)\n\n# Plotten der vorhergesagten Wahrscheinlichkeit, dass ein Kreis besetzt ist, in\n# Abhaengigkeit der erklaerenden Variable basierend auf den Modellresultaten.\n\nplot_model(m_day_count, type = \"pred\", terms = \"dist_road_scaled\")\n\n# Problem: skalierte Variablen lassen sich nicht so ohne Weiteres plotten, hier\n# ein quick-and-dirty hack um das Problem zu umgehen. Die Einstellungen muessen\n# fuer jede Variable geaendert werden\n\np <- plot_model(m_day_count, type = \"pred\", terms = \"dist_road_scaled\")\n\nlabels <- round(seq(floor(min(DF_mod_day$dist_road_all)), ceiling(max(DF_mod_day$dist_road_all)),\n    length.out = 6), 2)\n\np <- p + scale_x_continuous(breaks = c(-1, 0, 1, 2, 3, 4), labels = c(labels))\n\np\n```\n:::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}