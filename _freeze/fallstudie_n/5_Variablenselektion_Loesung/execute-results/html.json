{
  "hash": "8a0f1325e960fb36f67660e3e08e98b4",
  "result": {
    "markdown": "---\nexecute:\n  echo: true\nformat:\n  html:\n    code-tools:\n      source: true\n---\n\n\n# 5. Variablenselektion Multivariate Modelle / Habitatselektionsmodell - Lösung\n\n### Libraries laden\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Funktion um Packages direkt zu installieren und / oder zu laden\n\nipak <- function(pkg){\n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) \n    install.packages(new.pkg, repos = \"http://cran.us.r-project.org\", dependencies = TRUE)\n  sapply(pkg, require, character.only = TRUE)\n}\n\npackages <- c(\"sp\", \"raster\", \"tidyverse\", \"PerformanceAnalytics\", \"pastecs\", \"lme4\", \n              \"bbmle\", \"MuMIn\", \"MASS\", \"magrittr\")\n\nipak(packages)\n```\n:::\n\n\n### Variablenselektion\n**-> Vorgehen analog Coppes et al.**\n\n### Aufgabe 1\n\nMit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod <- read_delim(\"fallstudie_n/data/Aufgabe4_Datensatz_Habitatnutzung_Modelle_20221031_moodle.csv\", \n                     delim = \";\")\n\nDF_mod_day <- DF_mod |>\n  filter(time_of_day == \"day\")\n\nround(cor(DF_mod_day[,6:12], method = \"kendall\"),2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               slope dist_road_all dist_road_only dist_build forest_prop    us\nslope           1.00          0.13           0.16       0.11        0.18  0.22\ndist_road_all   0.13          1.00           0.84       0.02       -0.08 -0.06\ndist_road_only  0.16          0.84           1.00       0.03       -0.08 -0.04\ndist_build      0.11          0.02           0.03       1.00        0.42  0.12\nforest_prop     0.18         -0.08          -0.08       0.42        1.00  0.31\nus              0.22         -0.06          -0.04       0.12        0.31  1.00\nos              0.34         -0.06          -0.04       0.22        0.53  0.42\n                  os\nslope           0.34\ndist_road_all  -0.06\ndist_road_only -0.04\ndist_build      0.22\nforest_prop     0.53\nus              0.42\nos              1.00\n```\n:::\n\n```{.r .cell-code}\n# hier kann die Schwelle für die Korrelation gesetzt werden, 0.7 ist liberal / \n# 0.5 konservativ\n\ncor <- round(cor(DF_mod_day[,6:12], method = \"kendall\"),2) \ncor[abs(cor)<0.7] <-0\ncor\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               slope dist_road_all dist_road_only dist_build forest_prop us os\nslope              1          0.00           0.00          0           0  0  0\ndist_road_all      0          1.00           0.84          0           0  0  0\ndist_road_only     0          0.84           1.00          0           0  0  0\ndist_build         0          0.00           0.00          1           0  0  0\nforest_prop        0          0.00           0.00          0           1  0  0\nus                 0          0.00           0.00          0           0  1  0\nos                 0          0.00           0.00          0           0  0  1\n```\n:::\n:::\n\n\n### Aufgabe 2\n\n**Selektion der Variablen in einem univariaten Model**\n\nSkalieren der Variablen, damit ihr Einfluss vergleichbar wird (Problem verschiedene Skalen der Variablen (bspw. Neigung in Grad, Distanz in Metern))\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod_day %<>%\n  mutate(slope_scaled = scale(slope),\n         us_scaled = scale(us),\n         os_scaled = scale(os),\n         forest_prop_scaled = scale(forest_prop),\n         dist_road_all_scaled = scale(dist_road_all),\n         dist_road_only_scaled = scale(dist_road_only),\n         dist_build_scaled = scale(dist_build),\n         id = as.factor(id))\n```\n:::\n\n\n### Aufgabe 3\n\nEin erstes GLMM (Generalized Linear Mixed Effects Modell) aufbauen: Funktion und Modelformel\n\n> wichtige [Seite](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) auf der man viele Hilfestellungen zu GLMM’s finden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wir werden das package lme4 mit der Funktion glmer verwenden \n\n# die Hilfe von glmer aufrufen: ?glmer\n\n# glmer(formula, data = , family = binomial)\n\n# 1) formula: \n# Abhängige Variable ~ Erklärende Variable + Random Factor \n# In unseren Modellen kontrollieren wir für individuelle Unterschiede bei den Rehen \n# indem wir einen Random Factor definieren => (1 | id) \n\n# 2) data: \n# euer Datensatz\n\n# 3) family: \n# hier binomial\n\n# warum binomial? Verteilung Daten der Abhängigen Variable Präsenz/Absenz \n\nggplot(DF_mod_day, aes(pres_abs)) + geom_histogram()\n```\n\n::: {.cell-output-display}\n![](5_Variablenselektion_Loesung_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# --> Binäre Verteilung => Binomiale Verteilung mit n = 1 \n\n# und wie schaut die Verteilung der Daten der Abhängigen Variable Nutzungsintensität \n# (nmb, werden wir in diesem Kurs aber nicht genauer anschauen) aus?\n```\n:::\n\n\n### Aufgabe 4\n\nMit der GLMM Formel bauen wir in einem ersten Schritt eine univariate Variablenselektion auf.\n\n**Als abhängige Variable verwenden wir in der ersten Phase die Präsenz/Absenz der Rehe in den Kreisen**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Die erklärende Variable in m1 ist die erste Variable der korrelierenden\n# Beziehung Die erklärende Variable in m2 ist die zweite Variable der\n# korrelierenden Beziehung\n\n# Hier ein Beispiel: Tagmodell Distanz zu Strassen und Wegen versus Distanz zu\n# Strassen\n\nm1 <- glmer(pres_abs ~ dist_road_all_scaled + (1 | id), data = DF_mod_day, family = binomial)\nm2 <- glmer(pres_abs ~ dist_road_only_scaled + (1 | id), data = DF_mod_day, family = binomial)\n\n# mit dieser Funktion können die Modellergebnisse inspiziert werden\nsummary(m1)\n\n# Mit dieser Funktion kann der Informationgehalt der beiden Modelle\n# gegeneinander abgeschätzt werden\nbbmle::AICtab(m1, m2)\n\n# tieferer AIC -> besser (AIC = Akaike information criterion) -> als deltaAIC\n# ausgewiesen besser == Distanz zu Strassen\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden\n# Teildatensatz (geringe Störung/starke Störung) durchgeführt werden, um nur\n# noch nicht (R < 0.7) korrelierte Variablen in das Modell einfliessen zu\n# lassen\n```\n:::\n\n\n### Aufgabe 5\n\n**Selektion der Variablen in einem multivariaten Model**\n\nMit folgendem Code kann eine automatisierte Variablenselektion (dredge-Funktion) und ein Modelaveraging aufgebaut werden (siehe auch Stats-Skript von J.Dengler & Team)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V6 \n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)  \n\nf <- pres_abs ~ \n  slope_scaled +\n  us_scaled +\n  os_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_build_scaled \n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel \n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") %>% as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte \n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nsw(all_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                     dist_road_only_scaled forest_prop_scaled us_scaled\nSum of weights:      1.00                  1.00               1.00     \nN containing models:   32                    32                 32     \n                     slope_scaled dist_build_scaled os_scaled\nSum of weights:      0.95         0.67              0.39     \nN containing models:   32           32                32     \n```\n:::\n\n```{.r .cell-code}\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank=\"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmodel.avg(object = get.models(object = all_m, subset = delta < \n    2), rank = \"AICc\")\n\nComponent model call: \nglmer(formula = pres_abs ~ <3 unique rhs>, data = DF_mod_day, family = \n     binomial, na.action = na.fail)\n\nComponent models: \n       df   logLik    AICc delta weight\n12356   7 -2337.01 4688.05  0.00   0.48\n123456  8 -2336.48 4689.00  0.95   0.30\n2356    6 -2338.78 4689.58  1.53   0.22\n\nTerm codes: \n    dist_build_scaled dist_road_only_scaled    forest_prop_scaled \n                    1                     2                     3 \n            os_scaled          slope_scaled             us_scaled \n                    4                     5                     6 \n\nModel-averaged coefficients:  \n(full average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49073    0.14774     0.14778   3.321 0.000898 ***\ndist_build_scaled     -0.07877    0.06433     0.06434   1.224 0.220856    \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.01927    0.04529     0.04530   0.425 0.670597    \n \n(conditional average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49073    0.14774     0.14778   3.321 0.000898 ***\ndist_build_scaled     -0.10139    0.05508     0.05510   1.840 0.065755 .  \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.06466    0.06284     0.06286   1.029 0.303615    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# ==> für alle weiteren Datensätze muss der gleiche Prozess der Variablenselektion \n# durchgespielt werden. \n```\n:::\n",
    "supporting": [
      "5_Variablenselektion_Loesung_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}