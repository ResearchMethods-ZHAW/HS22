{
  "hash": "24544b875aeef53ec009e859df018b73",
  "result": {
    "markdown": "# 5. Lösung\n\n## Variablenselektion Multivariate Modelle / Habitatselektionsmodell\n\n\n\n\n\n### Libraries laden\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Funktion um Packages direkt zu installieren und / oder\n### zu laden\n\nipak <- function(pkg) {\n    new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n    if (length(new.pkg))\n        install.packages(new.pkg, repos = \"http://cran.us.r-project.org\",\n            dependencies = TRUE)\n    sapply(pkg, require, character.only = TRUE)\n}\n\npackages <- c(\"sp\", \"raster\", \"tidyverse\", \"PerformanceAnalytics\",\n    \"pastecs\", \"lme4\", \"bbmle\", \"MuMIn\", \"MASS\", \"magrittr\")\n\nipak(packages)\n```\n:::\n\n\n### Variablenselektion\n\n-> Vorgehen analog Coppes et al. \n\n### Aufgabe 1\n\nMit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod <- read_delim(\"data/Aufgabe4_Datensatz_Habitatnutzung_Modelle_20211101_moodle.csv\",\n    delim = \";\")\n\nDF_mod_day <- DF_mod %>%\n    filter(time_of_day == \"day\")\n\nround(cor(DF_mod_day[, 6:12], method = \"kendall\"), 2)\n\n# hier kann die Schwelle für die Korrelation gesetzt\n# werden, 0.7 ist liberal / 0.5 konservativ\n\ncor <- round(cor(DF_mod_day[, 6:12], method = \"kendall\"), 2)\ncor[abs(cor) < 0.7] <- 0\ncor\n```\n:::\n\n\n### Aufgabe 2\n\n**Selektion der Variablen in einem univariaten Model**\n\nSkalieren der Variablen, damit ihr Einfluss vergleichbar wird (Problem verschiedene Skalen der Variablen (bspw. Neigung in Grad, Distanz in Metern))\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod_day %<>%\n    mutate(slope_scaled = scale(slope), us_scaled = scale(us),\n        os_scaled = scale(os), forest_prop_scaled = scale(forest_prop),\n        dist_road_all_scaled = scale(dist_road_all),\n        dist_road_only_scaled = scale(dist_road_only),\n        dist_build_scaled = scale(dist_build), id = as.factor(id))\n```\n:::\n\n\n### Aufgabe 3\n\nEin erstes GLMM (Generalized Linear Mixed Effects Modell) aufbauen: Funktion und Modelformel\n\n> wichtige [Seite](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html) auf der man viele Hilfestellungen zu GLMM’s finden kann.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wir werden das package lme4 mit der Funktion glmer\n# verwenden ausserdem brauchen wir noch das package bbmle\n# --> installieren & laden\n\n# die Hilfe von glmer aufrufen: ?glmer\n\n# glmer(formula, data = , family = binomial)\n\n# 1) formula: Abhängige Variable ~ Erklärende Variable +\n# Random Factor In unseren Modellen kontrollieren wir für\n# individuelle Unterschiede bei den Rehen indem wir einen\n# Random Factor definieren => (1 | id)\n\n# 2) data: euer Datensatz\n\n# 3) family: hier binomial\n\n# warum binomial? Verteilung Daten der Abhängigen Variable\n# Präsenz/Absenz\n\nggplot(DF_mod_day, aes(pres_abs)) + geom_histogram()\n\n# --> Binäre Verteilung => Binomiale Verteilung mit n = 1\n\n# und wie schaut es bei der Verteilung der Daten der\n# Abhängigen Variable Nutzungsintensität (nmb) aus?\n\nggplot(DF_mod_day, aes(nmb)) + geom_histogram()\n\n# --> Negativbinomiale Verteilung\n```\n:::\n\n\n### Aufgabe 4\n\nMit der GLMM Formel bauen wir in einem ersten Schritt eine univariate Variablenselektion auf.\n\n**Als abhängige Variable verwenden wir in der ersten Phase die Präsenz/Absenz der Rehe in den Kreisen**\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Die erklärende Variable in m1 ist die erste Variable der\n# korrelierenden Beziehung Die erklärende Variable in m2\n# ist die zweite Variable der korrelierenden Beziehung\n\nm1 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 |\n    id), data = DF_mod_day, family = binomial)\nm2 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 |\n    id), data = DF_mod_day, family = binomial)\n\n# mit dieser Funktion können die Modellergebnisse\n# inspiziert werden\nsummary(m1)\n\n# Mit dieser Funktion kann der Informationgehalt der beiden\n# Modelle gegeneinander abgeschätzt werden\nbbmle::AICtab(m1, m2)\n\n# tieferer AIC -> besser (AIC = Akaike information\n# criterion) -> als deltaAIC ausgewiesen\n\n# Hier ein Beispiel: Distanz zu Strassen und Wegen versus\n# Distanz zu Strassen\n\nm1 <- glmer(pres_abs ~ dist_road_all_scaled + (1 | id), data = DF_mod_day,\n    family = binomial)\nm2 <- glmer(pres_abs ~ dist_road_only_scaled + (1 | id), data = DF_mod_day,\n    family = binomial)\n\n# summary(m1)\n\nbbmle::AICtab(m1, m2)\n\n# --> tiefer AIC -> besser == Distanz zu Strassen\n\n# ==> dieses Vorgehen muss nun für alle korrelierten\n# Variablen für jeden Teildatensatz (geringe Störung/starke\n# Störung) durchgeführt werden, um nur noch nicht (R < 0.7)\n# korrelierte Variablen in das Modell einfliessen zu lassen\n```\n:::\n\n\n### Aufgabe 5\n\n**Selektion der Variablen in einem multivariaten Model**\n\nMit folgendem Code kann eine automatisierte Variablenselektion (dredge-Funktion) und ein Modelaveraging aufgebaut werden (siehe auch Stats-Skript von J.Dengler & Team)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier wird die Formel für die dredge-Funktion vorbereitet\n# (die Variablen V1-V6 sind jene welche nach der\n# univariaten Variablenselektion noch übrig bleiben)\n\nf <- pres_abs ~ slope_scaled + us_scaled + os_scaled + forest_prop_scaled +\n    dist_road_only_scaled + dist_build_scaled\n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu\n# und es wird eine Formel daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") %>%\n    as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch\n# unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie\n# bedeutsam eine bestimmte Variable ist, wenn man viele\n# verschiedene Modelle vergleicht (multimodel inference))\n\nimportance(all_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (x) \nUseMethod(\"sw\")\n<bytecode: 0x000001e98e79f0b8>\n<environment: namespace:MuMIn>\n```\n:::\n\n```{.r .cell-code}\n# Schlussendlich wird ein Modelaverage durchgeführt\n# (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta <\n    2)\nsummary(avgmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmodel.avg(object = get.models(object = all_m, subset = delta < \n    2), rank = \"AICc\")\n\nComponent model call: \nglmer(formula = pres_abs ~ <3 unique rhs>, data = DF_mod_day, family = \n     binomial, na.action = na.fail)\n\nComponent models: \n       df   logLik    AICc delta weight\n12356   7 -2337.01 4688.05  0.00   0.48\n123456  8 -2336.48 4689.00  0.95   0.30\n2356    6 -2338.78 4689.58  1.53   0.22\n\nTerm codes: \n    dist_build_scaled dist_road_only_scaled    forest_prop_scaled \n                    1                     2                     3 \n            os_scaled          slope_scaled             us_scaled \n                    4                     5                     6 \n\nModel-averaged coefficients:  \n(full average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\ndist_build_scaled     -0.07877    0.06433     0.06434   1.224 0.220857    \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.01926    0.04529     0.04530   0.425 0.670605    \n \n(conditional average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\ndist_build_scaled     -0.10139    0.05508     0.05510   1.840 0.065756 .  \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.06466    0.06284     0.06286   1.029 0.303636    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# ==> für alle weiteren Datensätze muss der gleiche Prozess\n# der Variablenselektion durchgespielt werden.\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}