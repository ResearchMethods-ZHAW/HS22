{
  "hash": "d7cb647a8351dc1035698c569666a893",
  "result": {
    "markdown": "\n# 5. Lösung\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Variablenselektion Multivariate Modelle / Habitatselektionsmodell\n\n\n\n\n\n### libraries laden\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Funktion um Packages direkt zu installieren und / oder zu laden\n\nipak <- function(pkg){\n  new.pkg <- pkg[!(pkg %in% installed.packages()[, \"Package\"])]\n  if (length(new.pkg)) \n    install.packages(new.pkg, repos = \"http://cran.us.r-project.org\", dependencies = TRUE)\n  sapply(pkg, require, character.only = TRUE)\n}\n\npackages <- c(\"sp\", \"raster\", \"tidyverse\", \"PerformanceAnalytics\", \"pastecs\", \"lme4\", \n              \"bbmle\", \"MuMIn\", \"MASS\", \"magrittr\")\n\nipak(packages)\n```\n:::\n\n\n### Variablenselektion\n### -> Vorgehen analog Coppes et al. \n\n### Aufgabe 1: Mit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod <- read_delim(here(\"data\",\"Aufgabe4_Datensatz_Habitatnutzung_Modelle_20211101_moodle.csv\"), \n                     delim = \";\")\n\nDF_mod_day <- DF_mod %>%\n  filter(time_of_day == \"day\")\n\n\nround(cor(DF_mod_day[,6:12], method = \"kendall\"),2)\n\n# hier kann die Schwelle fuer die Korrelation gesetzt werden, 0.7 ist liberal / \n# 0.5 konservativ\n\ncor <- round(cor(DF_mod_day[,6:12], method = \"kendall\"),2) \ncor[abs(cor)<0.7] <-0\ncor\n```\n:::\n\n\n### Selektion der Variablen in einem univariaten Model\n\n### Aufgabe 2: Skalieren der Variablen, damit ihr Einfluss vergleichbar wird (Problem verschiedene Skalen der Variablen (bspw. Neigung in Grad, Distanz in Metern))\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDF_mod_day %<>%\n  mutate(slope_scaled = scale(slope),\n         us_scaled = scale(us),\n         os_scaled = scale(os),\n         forest_prop_scaled = scale(forest_prop),\n         dist_road_all_scaled = scale(dist_road_all),\n         dist_road_only_scaled = scale(dist_road_only),\n         dist_build_scaled = scale(dist_build),\n         id = as.factor(id))\n```\n:::\n\n\n### Aufgabe 3: Ein erstes GLMM (Generalized Linear Mixed Effects Modell) aufbauen: Funktion und Modelformel\n\n### wichtige Seite auf der man viele Hilfestellungen zu GLMM’s finden kann:\n### https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# wir werden das package lme4 mit der Funktion glmer verwenden \n# ausserdem brauchen wir noch das package bbmle\n# --> installieren & laden\n\n# die Hilfe von glmer aufrufen: ?glmer\n\n# glmer(formula, data = , family = binomial)\n\n# 1) formula: \n# Abhaengige Variable ~ Erklaerende Variable + Random Factor \n# In unseren Modellen kontrollieren wir fuer individuelle Unterschiede bei den Rehen \n# indem wir einen Random Factor definieren => (1 | id) \n\n# 2) data: \n# euer Datensatz\n\n# 3) family: \n# hier binomial\n\n# warum binomial? Verteilung Daten der Abhaengigen Variable Präsenz/Absenz \n\nggplot(DF_mod_day, aes(pres_abs)) + geom_histogram()\n\n# --> Binaere Verteilung => Binomiale Verteilung mit n = 1 \n\n# und wie schaut es bei der Verteilung der Daten der Abhaengigen Variable \n# Nutzungsintensitaet (nmb) aus?\n\nggplot(DF_mod_day, aes(nmb)) + geom_histogram()\n\n# --> Negativbinomiale Verteilung \n```\n:::\n\n\n### Aufgabe 4: Mit der GLMM Formel bauen wir in einem ersten Schritt eine univariate Variablenselektion auf.\n\n##### Als abhaengige Variable verwenden wir in der ersten Phase die Praesenz/Absenz der Rehe in den Kreisen\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Die erklaerende Variable in m1 ist die erste Variable der korrelierenden Beziehung\n# Die erklaerende Variable in m2 ist die zweite Variable der korrelierenden Beziehung\n\nm1 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id), data = DF_mod_day, \n            family = binomial)\nm2 <- glmer(Abhaengige_Variable ~ Erklaerende_Variable + (1 | id), data = DF_mod_day, \n            family = binomial)\n\n# mit dieser Funktion koennen die Modellergebnisse inspiziert werden\nsummary(m1)\n\n# Mit dieser Funktion kann der Informationgehalt der beiden Modelle gegeneinander \n# abgeschaetzt werden\nbbmle::AICtab(m1, m2)\n\n# tieferer AIC -> besser (AIC = Akaike information criterion) -> als deltaAIC ausgewiesen\n\n# Hier ein Beispiel: Distanz zu Strassen und Wegen versus Distanz zu Strassen\n\nm1 <- glmer(pres_abs ~ dist_road_all_scaled + (1 | id), data = DF_mod_day, \n            family = binomial)\nm2 <- glmer(pres_abs ~ dist_road_only_scaled + (1 | id), data = DF_mod_day, \n            family = binomial)\n\n# summary(m1)  \n\nbbmle::AICtab(m1, m2)\n\n# --> tiefer AIC -> besser == Distanz zu Strassen\n\n# ==> dieses Vorgehen muss nun für alle korrelierten Variablen für jeden Teildatensatz \n# (geringe Störung/starke Störung) durchgeführt werden, um nur noch nicht (R < 0.7) \n# korrelierte Variablen in das Modell einfliessen zu lassen \n```\n:::\n\n\n### Selektion der Variablen in einem multivariaten Model\n\n##### Aufgabe 5: Mit folgendem Code kann eine automatisierte Variablenselektion (dredge-Funktion) und ein Modelaveraging aufgebaut werden (siehe auch Stats-Skript von J.Dengler & Team)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# hier wird die Formel für die dredge-Funktion vorbereitet (die Variablen V1-V6 \n# sind jene welche nach der univariaten Variablenselektion noch übrig bleiben)  \n\nf <- pres_abs ~ \n  slope_scaled +\n  us_scaled +\n  os_scaled +\n  forest_prop_scaled +\n  dist_road_only_scaled +\n  dist_build_scaled \n\n# inn diesem Befehl kommt der Random-Factor (das Reh) hinzu und es wird eine Formel \n# daraus gemacht\n\nf_dredge <- paste(c(f, \"+ (1 | id)\"), collapse = \" \") %>% as.formula()\n\n# Das Modell mit dieser Formel ausführen\n\nm <- glmer(f_dredge, data = DF_mod_day, family = binomial, na.action = \"na.fail\")\n\n# Das Modell in die dredge-Funktion einfügen (siehe auch unbedingt ?dredge)\n\nall_m <- dredge(m)\n\n# Importance values der einzelnen Variablen (Gibt an, wie bedeutsam eine bestimmte \n# Variable ist, wenn man viele verschiedene Modelle vergleicht (multimodel inference))\n\nimportance(all_m)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: 'importance' is deprecated.\nUse 'sw' instead.\nSee help(\"Deprecated\")\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (x) \nUseMethod(\"sw\")\n<bytecode: 0x556968847eb8>\n<environment: namespace:MuMIn>\n```\n:::\n\n```{.r .cell-code}\n# Schlussendlich wird ein Modelaverage durchgeführt (Schwellenwert für das delta-AIC = 2)\n\navgmodel <- model.avg(all_m, rank=\"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmodel.avg(object = get.models(object = all_m, subset = delta < \n    2), rank = \"AICc\")\n\nComponent model call: \nglmer(formula = pres_abs ~ <3 unique rhs>, data = DF_mod_day, family = \n     binomial, na.action = na.fail)\n\nComponent models: \n       df   logLik    AICc delta weight\n12356   7 -2337.01 4688.05  0.00   0.48\n123456  8 -2336.48 4689.00  0.95   0.30\n2356    6 -2338.78 4689.58  1.53   0.22\n\nTerm codes: \n    dist_build_scaled dist_road_only_scaled    forest_prop_scaled \n                    1                     2                     3 \n            os_scaled          slope_scaled             us_scaled \n                    4                     5                     6 \n\nModel-averaged coefficients:  \n(full average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\ndist_build_scaled     -0.07877    0.06433     0.06434   1.224 0.220854    \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.01926    0.04529     0.04530   0.425 0.670605    \n \n(conditional average) \n                      Estimate Std. Error Adjusted SE z value Pr(>|z|)    \n(Intercept)           -0.49074    0.14774     0.14779   3.321 0.000898 ***\ndist_build_scaled     -0.10139    0.05508     0.05510   1.840 0.065753 .  \ndist_road_only_scaled  0.44281    0.04792     0.04793   9.239  < 2e-16 ***\nforest_prop_scaled     0.83786    0.06487     0.06489  12.912  < 2e-16 ***\nslope_scaled          -0.13548    0.04973     0.04975   2.723 0.006463 ** \nus_scaled              0.40130    0.04101     0.04102   9.784  < 2e-16 ***\nos_scaled              0.06466    0.06284     0.06286   1.029 0.303635    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n# ==> für alle weiteren Datensätze muss der gleiche Prozess der Variablenselektion \n# durchgespielt werden. \n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}