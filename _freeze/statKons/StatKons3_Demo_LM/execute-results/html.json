{
  "hash": "18b88276c7b146e94063db2913e52c45",
  "result": {
    "markdown": "---\ndate: 2022-11-21\nlesson: StatKons3\nthema: LM\nindex: 1\n---\n\n\n# StatKons3: Demo\n\n\n::: {.cell}\n::: {.cell-output .cell-output-error}\n```\nError in parse_block(g[-1], g[1], params.src, markdown_mode): Duplicate chunk label 'fig-plots-anova-example', which has been used for the chunk:\n# für mehr infos\n#https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\n\ncars <- mtcars %>% \n    mutate(cyl = as.factor(cyl)) %>% \n    slice(-31) # lösch die 31ste Zeile\n\n#Alternativ ginge auch das\ncars[-31,]\n\n# schaue daten zuerst mal an\n#1. Responsevariable\nhist(cars$hp) # nur sinnvoll bei grossem n\nboxplot(cars$hp)\n\n\n#2. Responsevariable ~ Prediktorvariable\ntable(cars$cyl) # mögliches probel, da n's unterschiedlich gross\n\nboxplot(cars$hp ~ cars$cyl) # varianzheterogentität weniger das problem, \n# aber normalverteilung der residuen problematisch\n\n# definiere das modell für eine ein-faktorielle anova\naov.1 <- aov(log10(hp) ~ cyl, data = cars)\n\n#3. Schaue Modelgüte an\npar(mfrow = c(2,2))\nplot(aov.1)\n\n#4. Schaue output an und ordne es ein\nsummary.lm(aov.1)\n\n#5. bei meheren Kategorien wende einen post-hoc Vergleichstest an\nTukeyHSD(aov.1)\n\n#6. Ergebnisse passend darstellen\nlibrary(multcomp)\n\n#erstens die signifikanten Unterschiede mit Buchstaben versehen\nletters <- multcomp::cld(multcomp::glht(aov.1, linfct=multcomp::mcp(cyl=\"Tukey\"))) # Achtung die kategoriale\n#Variable (unsere unabhängige Variable \"cyl\") muss als Faktor\n#definiert sein z.B. as.factor()\n\n#einfachere Variante\nboxplot(hp ~ cyl, data = cars)\nmtext(letters$mcletters$Letters, at=1:3)\n\n#schönere Variante :)\nggplot(cars, aes(x = cyl, y = hp)) +\n\tstat_boxplot(geom = \"errorbar\", width = .5) +\n  geom_boxplot(size = 1) +\n\tannotate(\"text\", x = 1, y = 350, label = \"a\", size = 7)+\nannotate(\"text\", x = 2, y = 350, label = \"b\", size = 7)+\n  annotate(\"text\", x = 3, y = 350, label = \"c\", size = 7)\n  labs(x = \"\\nAnzahl Zylinder\", y = \"Pferdestärke\")  +\n  mytheme\n\n#Plot exportieren\nggsave(filename = \"statKons/distill-preview.png\",\n       device = \"png\") # hier kann man festlegen, was für ein Bildformat\n#exportiert werden möchte\n\n# Sind die Voraussetzungen für eine Anova verletzt, überprüfe alternative \n# nicht-parametische Tests z.B. oneway-Test mit Welch-korrektur für ungleiche\n# Varianzen (Achtung auch dieser Test hat Voraussetzungen -> siehe Skript XY)\nlibrary(rosetta)\nwelch1 <- oneway.test(hp ~ cyl, data = cars, var.equal = FALSE)\nrosetta::posthocTGH(cars$hp, cars$cyl, method = \"games-howell\")\n```\n:::\n:::\n\n\n> Download [R-Skript](../purl/StatKons3_Demo_LM.R)\n\n\n\n\n\n## Einfaktorielle ANOVA\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# für mehr infos\n#https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/mtcars.html\n\ncars <- mtcars %>% \n    mutate(cyl = as.factor(cyl)) %>% \n    slice(-31) # lösch die 31ste Zeile\n\n#Alternativ ginge auch das\ncars[-31,]\n\n# schaue daten zuerst mal an\n#1. Responsevariable\nhist(cars$hp) # nur sinnvoll bei grossem n\nboxplot(cars$hp)\n\n\n#2. Responsevariable ~ Prediktorvariable\ntable(cars$cyl) # mögliches probel, da n's unterschiedlich gross\n\nboxplot(cars$hp ~ cars$cyl) # varianzheterogentität weniger das problem, \n# aber normalverteilung der residuen problematisch\n\n# definiere das modell für eine ein-faktorielle anova\naov.1 <- aov(log10(hp) ~ cyl, data = cars)\n\n#3. Schaue Modelgüte an\npar(mfrow = c(2,2))\nplot(aov.1)\n\n#4. Schaue output an und ordne es ein\nsummary.lm(aov.1)\n\n#5. bei meheren Kategorien wende einen post-hoc Vergleichstest an\nTukeyHSD(aov.1)\n\n#6. Ergebnisse passend darstellen\nlibrary(multcomp)\n\n#erstens die signifikanten Unterschiede mit Buchstaben versehen\nletters <- multcomp::cld(multcomp::glht(aov.1, linfct=multcomp::mcp(cyl=\"Tukey\"))) # Achtung die kategoriale\n#Variable (unsere unabhängige Variable \"cyl\") muss als Faktor\n#definiert sein z.B. as.factor()\n\n#einfachere Variante\nboxplot(hp ~ cyl, data = cars)\nmtext(letters$mcletters$Letters, at=1:3)\n\n#schönere Variante :)\nggplot(cars, aes(x = cyl, y = hp)) +\n\tstat_boxplot(geom = \"errorbar\", width = .5) +\n  geom_boxplot(size = 1) +\n\tannotate(\"text\", x = 1, y = 350, label = \"a\", size = 7)+\nannotate(\"text\", x = 2, y = 350, label = \"b\", size = 7)+\n  annotate(\"text\", x = 3, y = 350, label = \"c\", size = 7)\n  labs(x = \"\\nAnzahl Zylinder\", y = \"Pferdestärke\")  +\n  mytheme\n\n#Plot exportieren\nggsave(filename = \"statKons/distill-preview.png\",\n       device = \"png\") # hier kann man festlegen, was für ein Bildformat\n#exportiert werden möchte\n\n# Sind die Voraussetzungen für eine Anova verletzt, überprüfe alternative \n# nicht-parametische Tests z.B. oneway-Test mit Welch-korrektur für ungleiche\n# Varianzen (Achtung auch dieser Test hat Voraussetzungen -> siehe Skript XY)\nlibrary(rosetta)\nwelch1 <- oneway.test(hp ~ cyl, data = cars, var.equal = FALSE)\nrosetta::posthocTGH(cars$hp, cars$cyl, method = \"games-howell\")\n```\n:::\n\n\n## Mehrfaktorielle ANOVA\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-anova-example-1.png){#fig-plots-multi-anova-example width=672}\n:::\n:::\n\n\n## Einfache Regression\n\n::: {.cell}\n\n```{.r .cell-code}\n# inspiriert von Simon Jackson: http s://drsimonj.svbtle.com/visualising-residuals\ncars <- mtcars %>% \n  #ändere die unabhängige Variable mpg in 100Km/L\n  mutate(kml = (235.214583/mpg)) # mehr Infos hier: https://www.asknumbers.com/mpg-to-L100km.aspx\n  # %>%  # klone data set\n  # slice(-31) # # lösche Maserrati und schaue nochmals Modelfit an\n\n#############\n##1.Daten anschauen\n############\n\n# Zusammenhang mal anschauen\n# Achtung kml = 100km pro Liter \nplot(hp ~ kml, data = cars)\n\n# Responsevariable anschauen\nboxplot(cars$hp)\n\n# Korrelationen uv + av anschauen\n# Reihenfolge spielt hier keine Rolle, wieso?\ncor(cars$kml, cars$hp) # hängen stark zusammen\n\n###################\n#2. Modell definieren: einfache regression\n##################\nmodel <- lm(hp ~ kml, data = cars)\nsummary.lm(model)\n\n###############\n#3.Modeldiagnostik und ggf. Anpassungen ans Modell oder ähnliches\n###############\n\n# semi schöne Ergebnisse\nlibrary(ggfortify)\nggplot2::autoplot(model) + mytheme # gitb einige Extremwerte => was tun? (Eingabe/Einlesen \n#überprüfen, Transformation, Extremwerte nur ausschliessen mit guter Begründung)\n\n# erzeuge vorhergesagte Werte und Residualwerte\ncars$predicted <- predict(model)   # bilde neue Variable mit geschätzten y-Werten\ncars$residuals <- residuals(model)\n\n# schaue es dir an, sieht man gut was die Residuen sind\nd <- cars %>%  \n    dplyr::select(hp, kml, predicted, residuals)\n\n# schauen wir es uns an\nhead(d, 4)\n\n#visualisiere residuen\nggplot(d, aes(x = kml, y = hp)) +\n  # verbinde beobachtete werte mit vorausgesagte werte\n  geom_segment(aes(xend = kml, yend = predicted)) + \n  geom_point() + # Plot the actual points\n  geom_point(aes(y = predicted), shape = 4) + # plot geschätzten y-Werten\n  # geom_line(aes(y = predicted), color = \"lightgrey\") # alternativ code\n  geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n  # Farbe wird hier zu den redisuen gemapped, abs(residuals) wegen negativen zahlen  \n  geom_point(aes(color = abs(residuals))) + \n  # Colors to use here (für mehrere farben verwende color_gradient2)\n  scale_color_continuous(low = \"blue\", high = \"red\") +  \n  scale_x_continuous(limits = c(0, 40)) +\n  scale_y_continuous(limits = c(0, 300)) +\n  guides(color = \"none\") +  # Color legende entfernen\n  labs(x = \"\\nVerbraucht in Liter pro 100km\", y = \"Motorleistung in PS\\n\") +\n  mytheme\n\n##########\n#4. plotte Ergebnis\n##########\nggplot(d, aes(x = kml, y = hp)) +\n    geom_point(size = 4) +\n    # geom_point(aes(y = predicted), shape = 1, size = 4) +\n    # plot regression line\n    geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n    #intercept\n    geom_line(aes(y = mean(hp)), color = \"blue\") +\n    mytheme\n```\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-regression-example-1.png){#fig-plots-regression-example-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-regression-example-2.png){#fig-plots-regression-example-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-regression-example-3.png){#fig-plots-regression-example-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-regression-example-4.png){#fig-plots-regression-example-4 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-regression-example-5.png){#fig-plots-regression-example-5 width=672}\n:::\n:::\n\n\n## Multiple regression\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Select data\ncars <- mtcars %>% \n    slice(-31) %>%\n    mutate(kml = (235.214583/mpg)) %>% \n    dplyr::select(kml, hp, wt, disp)\n\n################\n# 1. Multikollinearitüt überprüfen\n# Korrelation zwischen Prädiktoren kleiner .7\ncor <- cor(cars[, -2])\ncor[abs(cor)<0.7] <- 0  \ncor # \n\n##### info zu Variablen\n#wt = gewicht\n#disp = hubraum\n\n###############\n#2. Responsevariable + Kriteriumsvariable anschauen\n##############\n# was würdet ihr tun?\n\n############\n#3. Definiere das Model\n############\nmodel1 <- lm(hp ~ kml + wt + disp, data = cars) \nmodel2 <- lm(hp ~ kml + wt, data = cars)\nmodel3 <- lm(log10(hp) ~ kml + wt, data = cars)\n\n#############\n#4. Modeldiagnostik\n############\n\nlibrary(ggfortify)\nggplot2::autoplot(model1)\nggplot2::autoplot(model2) # besser, immernoch nicht ok => transformation? vgl. model3\nggplot2::autoplot(model3)\n\n############\n#5. Modellfit vorhersagen: wie gut sagt mein Modell meine Daten vorher\n############\n\n#es gibt 3 Mögliche Wege\n\n# gebe dir predicted values aus für model2 (für vorzeigebeispiel einfacher :)\n# gibts unterschidliche varianten die predicted values zu berechnen\n# 1. default funktion predict(model) verwenden\ncars$predicted <- predict(model2)\n\n# 2. datensatz selber zusammenstellen (nicht empfohlen): wichtig, die \n# prädiktoren müssen denselben\n# namen haben wie im Model\n# besser mit Traindata von Beginn an mehr Infos hier: https://www.r-bloggers.com/using-linear-regression-to-predict-energy-output-of-a-power-plant/\n\nnew.data <- tibble(kml = sample(seq(6.9384, 22.61, .3), 31),\n                   wt = sample(seq(1.513, 5.424, 0.01), 31),\n                   disp = sample(seq(71.1, 472.0, .1), 31)) \ncars$predicted_own <- predict(model2, newdata = new.data)\n\n# 3. train_test_split durchführen (empfohlen) muss jedoch von beginn an bereits \n# gemacht werden - Logik findet ihr hier: https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6 oder https://towardsdatascience.com/6-amateur-mistakes-ive-made-working-with-train-test-splits-916fabb421bb\n# beispiel hier: https://ijlyttle.github.io/model_cv_selection.html\ncars <- mtcars %>% \n  mutate(id = 1:nrow(.)) %>%  # für das mergen der Datensätze\n  mutate(kml = (235.214583/mpg)) %>% \n  dplyr::select(kml, hp, wt, disp, id)\n  \ntrain_data <- cars %>% \n  dplyr::sample_frac(.75) # für das Modellfitting\n\ntest_data  <- dplyr::anti_join(cars, train_data, by = 'id') # für den Test mit predict\n\n# erstelle das Modell und \"trainiere\" es auf den train Datensatz\nmodel2_train <- lm(hp ~ kml + wt, data = train_data)\n\n# mit dem \"neuen\" Datensatz wird das Model überprüft ob guter Modelfit\ntrain_data$predicted_test <- predict(model2_train, newdata = test_data)\n\n# Residuen\ntrain_data$residuals <- residuals(model2_train)\nhead(train_data)\n\n#weiterführende Infos zu \"machine learning\" Idee hier: https://stat-ata-asu.github.io/MachineLearningToolbox/regression-models-fitting-them-and-evaluating-their-performance.html\n#wichtigstes Packet in dieser Hinsicht ist \"caret\": https://topepo.github.io/caret/\n#beste Philosophie ist tidymodels: https://www.tidymodels.org\n\n#----------------\n# Schnelle variante mit broom\nd <- lm(hp ~ kml + wt+ disp, data = cars) %>% \n    broom::augment()\n\nhead(d)\n\nggplot(d, aes(x = kml, y = hp)) +\n    geom_segment(aes(xend = kml, yend = .fitted), alpha = .2) +\n    geom_point(aes(color = .resid)) +\n    scale_color_gradient2(low = \"blue\", mid = \"white\", high = \"red\") +\n    guides(color = \"none\") +\n    geom_point(aes(y = .fitted), shape = 4) +\n    scale_y_continuous(limits = c(0,350)) +\n    geom_smooth(method = \"lm\", se = FALSE, color = \"lightgrey\") +\n    mytheme\n\n############\n# 6. Modellvereinfachung\n############\n\n# Varianzpartitionierung\nlibrary(hier.part)\ncars <- mtcars %>% \n  mutate(kml = (235.214583/mpg)) %>% \n  select(-mpg)\n\nnames(cars) # finde \"position\" deiner Responsevariable\n\nX = cars[, -3] # definiere all die Prädiktorvariablen im Model (minus Responsevar)\n\n# dauert ein paar sekunden\nhier.part(cars$hp, X, gof = \"Rsqu\")\n\n# alle Modelle miteinander vergleichen mit dredge Befehl: geht nur bis \n# maximal 15 Variablen\nmodel2 <- lm(hp ~ ., data = cars)\nlibrary(MuMIn)\noptions(na.action = \"na.fail\")\nallmodels <- dredge(model2)\nhead(allmodels)\n\n# Wichtigkeit der Prädiktoren\nMuMIn::importance(allmodels)\n\n# mittleres Model\navgmodel<- MuMIn::model.avg(get.models(allmodels, subset=TRUE))\nsummary(avgmodel)\n\n# adäquatest model gemäss multimodel inference\nmodel_ad <- lm(hp ~ carb + disp + wt, data = mtcars)\nsummary(model_ad)\n```\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-regression-example-1.png){#fig-plots-multi-regression-example-1 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-regression-example-2.png){#fig-plots-multi-regression-example-2 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-regression-example-3.png){#fig-plots-multi-regression-example-3 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-regression-example-4.png){#fig-plots-multi-regression-example-4 width=672}\n:::\n\n::: {.cell-output-display}\n![Generierter Plot](StatKons3_Demo_LM_files/figure-html/fig-plots-multi-regression-example-5.png){#fig-plots-multi-regression-example-5 width=672}\n:::\n:::\n",
    "supporting": [
      "StatKons3_Demo_LM_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}