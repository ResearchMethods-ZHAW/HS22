{
  "hash": "2a09d0b2be46c08609c408af6f5d00d6",
  "result": {
    "markdown": "---\ntitle: \"Übung 2S - Lösung\"\nauthor:  Gian-Andrea Egeler\nimage: distill-preview-2s.png\nlerneinheit: Statistik4\ndate: 2021-11-09\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n::: {.cell}\n\n:::\n\n\n>Download [R-Skript](Statistik4_Loesung_2s.R) \n\n# Musterlösung Übung 4.2S: Multiple logistische Regression (SozWis)\n\n*****\n- **Lese-Empfehlung** Kapitel 6 von [Manny Gimond]( https://mgimond.github.io/Stats-in-R/Logistic.html)\n- **Lese-Empfehlung** Kapitel 4 von [Gareth (2016)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf)\n- **Lese-Empfehlung** Vorlesungsfolien von Oscar Torres-Reyna [Princeton University](https://www.princeton.edu/~otorres/LogitR101.pdf)\n*****\n\n## kommentierter Loesungsweg\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Genereiert eine Dummyvariable: Fleisch 1, kein Fleisch 0\ndf <- nova_survey %>%  # kopiert originaler Datensatz\n  rename(umwelteinstellung = tho_2) %>% # änderung name der variable\n  mutate(umwelteinstellung = case_when(umwelteinstellung == 4 ~ 1,\n                                       umwelteinstellung == 3 ~ 1,\n                                       umwelteinstellung == 2 ~ 0, \n                                       umwelteinstellung == 1 ~ 0)) %>% \n  # lasse die kleine Gruppe mit x weg\n  dplyr::filter(!str_detect(string = \"x\", gender)) %>% \n  # lasse die kleine Gruppe \"andere\" weg\n  dplyr::filter(!str_detect(string = \"Andere\", member)) %>%  \n  # wähle nur die relevanten variablen aus\n  dplyr::select(mensa, age_groups, gender, member, umwelteinstellung, meat) \n\n# Schaut euch die Missings an in der Kriteriumsvariable \"mensa\"\nsum(is.na(df$mensa))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0\n```\n:::\n\n```{.r .cell-code}\n# schaut euch die Missings an in den Prädiktorvariablen \"Alter\", \"Geschlecht\", \"Hochschulzugehörigkeit\", \"Umwelteinstellung\"\n\nAmelia::missmap(df) \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `arguments`.\nUnknown or uninitialised column: `arguments`.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Unknown or uninitialised column: `imputations`.\n```\n:::\n\n::: {.cell-output-display}\n![](Statistik4_Loesung_2s_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# vieles deutet darauf hin, dass die missings (fehlende Werte) \n# zufällig zustande gekommen sind (sog. MCAR); für mehr Informationen: https://uvastatlab.github.io/2019/05/01/getting-started-with-multiple-imputation-in-r/\n\n# bester Weg wäre, die wenigen fehlenden Werte zu imputieren; \n# einfachheitshalber löschen wir sie aber :)\ndf %<>%\n  drop_na()\n\n#  sieht euch die Verteilung zwischen Mensagänger und Selbstverpfleger an\n# sind nicht gleichmässig verteilt, bei der Vorhersage müssen wir das berücksichtigen\ntable(df$mensa) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n  0   1 \n282 786 \n```\n:::\n\n```{.r .cell-code}\ndf %>% count(mensa) # alternativ\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  mensa     n\n  <dbl> <int>\n1     0   282\n2     1   786\n```\n:::\n\n```{.r .cell-code}\n# definiert das logistische Modell und wendet es auf den Datensatz an\n\nmod0 <-glm(mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n           data = df, binomial(\"logit\"))\nsummary.lm(mod0) # Umwelteinstellung scheint keinen Einfluss auf die \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat + umwelteinstellung, \n    family = binomial(\"logit\"), data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-5.6740 -0.8078  0.3712  0.5867  1.2379 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                  -0.18889    0.40225  -0.470 0.638750    \ngenderMann                    0.71017    0.16018   4.434 1.02e-05 ***\nmemberStudent/in             -0.63072    0.29442  -2.142 0.032404 *  \nage_groups26- bis 34-jaehrig  1.09429    0.19574   5.591 2.88e-08 ***\nage_groups35- bis 49-jaehrig  1.75379    0.45968   3.815 0.000144 ***\nage_groups50- bis 64-jaehrig  2.43530    0.78923   3.086 0.002083 ** \nmeat                          0.19945    0.05055   3.945 8.49e-05 ***\numwelteinstellung             0.19334    0.18688   1.035 0.301107    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.009 on 1060 degrees of freedom\nMultiple R-squared:  0.004042,\tAdjusted R-squared:  -0.002536 \nF-statistic: 0.6145 on 7 and 1060 DF,  p-value: 0.7443\n```\n:::\n\n```{.r .cell-code}\n# Verpflegung zu haben, gegeben die Daten\n\n# neues Modell ohne Umwelteinstellung\nmod1 <- update(mod0, ~. -umwelteinstellung)\nsummary.lm(mod1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = mensa ~ gender + member + age_groups + meat, family = binomial(\"logit\"), \n    data = df)\n\nWeighted Residuals:\n    Min      1Q  Median      3Q     Max \n-6.0117 -0.8060  0.3584  0.6100  1.2407 \n\nCoefficients:\n                             Estimate Std. Error t value Pr(>|t|)    \n(Intercept)                   0.03212    0.34053   0.094 0.924860    \ngenderMann                    0.69697    0.15951   4.369 1.37e-05 ***\nmemberStudent/in             -0.64418    0.29426  -2.189 0.028806 *  \nage_groups26- bis 34-jaehrig  1.11651    0.19458   5.738 1.25e-08 ***\nage_groups35- bis 49-jaehrig  1.77409    0.45947   3.861 0.000120 ***\nage_groups50- bis 64-jaehrig  2.44683    0.78953   3.099 0.001992 ** \nmeat                          0.18070    0.04709   3.837 0.000132 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.01 on 1061 degrees of freedom\nMultiple R-squared:  0.003998,\tAdjusted R-squared:  -0.001635 \nF-statistic: 0.7098 on 6 and 1061 DF,  p-value: 0.6418\n```\n:::\n\n```{.r .cell-code}\n# Modeldiagnostik (wenn nicht signifikant, dann OK)\n1 - pchisq(mod1$deviance, mod1$df.resid) # Ok\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.4509591\n```\n:::\n\n```{.r .cell-code}\n#Modellgüte (pseudo-R²)\n1 - (mod1$dev / mod1$null) # eher kleines pseudo-R2, deckt sich mit dem R-Squared aus dem obigen output summary.lm()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.1354244\n```\n:::\n\n```{.r .cell-code}\n# Konfusionsmatrix vom  Datensatz\n# Model Vorhersage\n# hier ein anderes Beispiel: \npredicted <- predict(mod1, df, type = \"response\")\n\n# erzeugt eine Tabelle mit den beobachteten\n# Mensagänger/Selbstverpfleger und den Vorhersagen des Modells\nkm <- table(predicted > 0.5, df$mensa) \n# alles was höher ist als 50% ist \n# kommt in die Kategorie Mensagänger\n\n# anpassung der namen\ndimnames(km) <- list(\n  c(\"Modell Selbst\", \"Modell Mensa\"),\n  c(\"Daten Selbst\", \"Daten Mensa\"))\nkm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              Daten Selbst Daten Mensa\nModell Selbst           87          59\nModell Mensa           195         727\n```\n:::\n\n```{.r .cell-code}\n#############\n### reminder: https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62\n#############\n\n#TP = true positive: you predicted positive and it’s true; hier vorhersage \n# mensagänger stimmt also (727)\n\n#TN = true negative: you predicted negative and it’s true, hier vorhersage der \n# selbstverpfleger stimmt (87)\n\n#FP = false positive (fehler 1. art, auch spezifizität genannt) you predicted \n# and it’s false. hier modell sagt mensagänger vorher \n# (obwohl in realität selbstverpfleger) (195)\n\n#FN = false negative (fehler 2. art, auch sensitivität genannt), \n# you predicted negative and it’s false. hier modell sagt selbtverpfleger vorher \n# (obwohl in realität mensagänger) (59)\n\n\n# es scheint, dass das Modell häufig einen alpha Fehler zu machen, d.h. es \n# das Modell weist keine hohe Spezifizität auf: konkret werden viele Mensagänger als \n# Selbstverpfleger vorhergesagt resp. klassifiziert. Dafür gibt es mehere Gründe: \n\n#1) die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger\n# Selbstverpfleger als Mensgänger im Datensatz \n \n#2) nicht adäquates Modell z.B. link mit probit zeigt besserer fit\n\n#3) Overfitting: wurde hier nicht berücksichtigt, in einem Paper/Arbeit \n# müsste noch einen Validierungstest gemacht werden z.B. test-train \n# Cross-Validation oder k fold Cross-Validation \n\n# kalkuliert die Missklassifizierungsrate \nmf <- 1-sum(diag(km)/sum(km)) # ist mit knapp 23 %  eher hoch\nmf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2378277\n```\n:::\n\n```{.r .cell-code}\n# kleiner exkurs: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/\n# col wise proportion, da diese die \"realität\" ist\nkm_prop <- prop.table(km,2)\n\n# specificity = a / (a+c) => ability of a test to correctly \n# classify an individual as disease-free is called the test′s specificity\nspec = km_prop[1] / (km_prop[1] + km_prop[2])\nspec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3085106\n```\n:::\n\n```{.r .cell-code}\n# sensitivity = d / (b+d) => Sensitivity is the ability of a \n# test to correctly classify an individual as ′diseased′\nsens = km_prop[4] / (km_prop[3] + km_prop[4])\nsens\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.9249364\n```\n:::\n:::\n\n\n## Methode\n\nIn der Aufgabe war es das Ziel zu schauen, ob wir einen potenziellen Besuch eines Mensagasts vorhersagen können und zwar in Abhängigkeit von den sozioökonimischen Variablen, wahrgenommene Fleischkonsum und der Umwelteinstellung. Die Kriteriumsvariable \"Mensa\" weist eine binäre Verteilung auf: Deshalb rechnen wir eine multiple logistische Regression mit den Prädiktoren “Alter”, “Geschlecht”, “Hochschulzugehörigkeit”, \"Fleischkonsum\" und \"Umwelteinstellung. Mehr Informatinen zu den logistischen Regressinen findet ihr im Buch von Crawley (2015) oder auch im Buch von [Gareth (2016)](http://faculty.marshall.usc.edu/gareth-james/ISL/ISLR%20Seventh%20Printing.pdf), Kapitel 4.3; passendes Video [hier](https://www.youtube.com/watch?v=31Q5FGRnxt4&list=PL5-da3qGB5IC4vaDba5ClatUmFppXLAhE&index=2).\n\n## Ergebnisse\n\n::: {.cell}\n::: {.cell-output-display}\n|              | Daten Selbst| Daten Mensa|\n|:-------------|------------:|-----------:|\n|Modell Selbst |           87|          59|\n|Modell Mensa  |          195|         727|\n\n\n\nKonfusionsmatrix\n:::\n:::\n\n\nDer Output des logistischen Models mit der Linkfunktin \"logit\" sagt und, dass das Modell nicht gut zu den Daten passt, d.h. mit dem Modell (gegeben die Daten) können wir nur schlecht vorhersagen, ob eine Person zukünftig sich in der Mensa verpflegt oder ihr Mittagessen selber mitnimmt. Hinweise dafür geben das kleine pseudo-R2 (14%) als auch die hohe Missklassifizierungsrate (24%): bei genauerer Betrachtung fällt auf, dass das Modell häufig einen alpha-Fehler begeht, d.h. unser Modell sagt zu viele Mensagänger vorher, obwohl diese in Realität Selbstverpfleger sind. \nEs gibt verschiedene Gründe für diesen schlechten Modelfit:\n\n* die Kriteriumsvariable ist sehr ungleich verteilt, d.h. es gibt weniger Selbstverpfleger als Mensgänger im Datensatz (26% vs. 74%)\n* die Prädiktorvariablen sind alle entweder kategorial oder ordinal: dies kann dazu führen, dass das Model keinen guten fit zu den Daten erzielt \n\n**Fazit**: Es sollte nach einem weiteren adäquateren Modell gesucht werden: insbesondere ein Modell, welches einen mit ordinalen Prädiktorvariablen umgehen kann: \n\n- eine bessere Link-Funktion für das GLM suchen z.B. probit \n- [polynomiale Kontraste](https://stats.stackexchange.com/questions/195246/how-to-handle-ordinal-categorical-variable-as-independent-variable)\n- Smooth Splines [hier](https://www.frontiersin.org/articles/10.3389/fams.2017.00015/full)\n- multinomiale Regression z.M. nnet::mulitom()[hier](https://stats.idre.ucla.edu/r/dae/multinomial-logistic-regression/) \n",
    "supporting": [
      "Statistik4_Loesung_2s_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}