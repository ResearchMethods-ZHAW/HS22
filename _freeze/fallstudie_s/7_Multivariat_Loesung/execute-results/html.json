{
  "hash": "aa3165eb9a32d2273c27b5256fa0e7ce",
  "result": {
    "markdown": "# KW 44: Lösung Multivariat\n\n\n\n\n\n\n\n\n\n# Aufgabe 1: Verbinden von Daten (Join)\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Erstelle ein df indem die taeglichen Zaehldaten und Meteodaten vereint sind\numwelt <- inner_join(depo_d, meteo, by = c(\"Datum\" = \"time\"))\n```\n:::\n\n\n# Aufgabe 2: Convenience Variablen, Faktoren, Skalieren\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Wir muessen unserem Daten noch zuweisen, ob Ferienzeit oder nicht. Das machen wir mit einer Funktion\n# erstelle zuerst ein dataframe zur Zuweisung der Ferien # credits Melina Grether\n\nStart <- c(Winterferien_2016_start, Fruehlingsferien_2017_start, Sommerferien_2017_start, Herbstferien_2017_start, \n           Winterferien_2017_start, Fruehlingsferien_2018_start, Sommerferien_2018_start, Herbstferien_2018_start,\n           Winterferien_2019_start, Fruehlingsferien_2019_start, Sommerferien_2019_start, Herbstferien_2019_start,\n           Winterferien_2020_start, Fruehlingsferien_2020_start, Sommerferien_2020_start, Herbstferien_2020_start,\n           Winterferien_2021_start, Fruehlingsferien_2021_start, Sommerferien_2021_start, Herbstferien_2021_start,\n           Winterferien_2022_start, Fruehlingsferien_2022_start, Sommerferien_2022_start, Herbstferien_2022_start)\nEnd <- c(Winterferien_2016_ende, Fruehlingsferien_2017_ende, Sommerferien_2017_ende, Herbstferien_2017_ende, \n         Winterferien_2017_ende, Fruehlingsferien_2018_ende, Sommerferien_2018_ende, Herbstferien_2018_ende,\n         Winterferien_2019_ende, Fruehlingsferien_2019_ende, Sommerferien_2019_ende, Herbstferien_2019_ende,\n         Winterferien_2020_ende, Fruehlingsferien_2020_ende, Sommerferien_2020_ende, Herbstferien_2020_ende,\n         Winterferien_2021_ende, Fruehlingsferien_2021_ende, Sommerferien_2021_ende, Herbstferien_2021_ende,\n         Winterferien_2022_ende, Fruehlingsferien_2022_ende, Sommerferien_2022_ende, Herbstferien_2022_ende)\n\n# verbinde das zu einem df\nferien <- data.frame(Start, End)\n\n# schreibe nun eine Funktion zur zuweisung Ferien. WENN groesser als start UND kleiner als\n# ende, DANN schreibe ein 1\nfor (i in 1:nrow(ferien)){\n  umwelt$Ferien[umwelt$Datum >= ferien[i,\"Start\"] & umwelt$Datum <= ferien[i,\"End\"]] <- 1\n}\numwelt$Ferien[is.na(umwelt$Ferien)] <- 0\n\n# hat das funktioniert? zaehle die anzahl Ferientage\nsum(umwelt$Ferien)\n\n# Faktor und integer\n# Im GLMM wird das Jahr als random factor definiert. Dazu muss es als\n# Faktor vorliegen. Monat und KW koennen die Besuchszahlen auch erklaeren.\n# auch sie muessen faktoren sein\numwelt <- umwelt |> \n  mutate(Jahr = as.factor(Jahr)) |> \n  mutate(KW = as.factor(KW)) |>\n  mutate(Monat = as.factor(Monat)) |>\n  # zudem muessen die die nummerischen Wetterdaten auch als solche abgespeichert sein\n  mutate(tre200nx = as.numeric(tre200nx))|>\n  mutate(tre200jx = as.numeric(tre200jx))|>\n  mutate(rre150j0 = as.numeric(rre150j0))|>\n  mutate(rre150n0 = as.numeric(rre150n0))|>\n  mutate(sremaxdv = as.numeric(sremaxdv))\n\n# falls das noch zu NA's gefuehrt hat, muessen diese entfernt werden\nsum(is.na(umwelt))\numwelt <- na.omit(umwelt)\nsummary(umwelt)\nstr(umwelt)\n\n# Unser Modell kann nur mit ganzen Zahlen umgehen. Zum Glueck habe wir die Zaehldaten\n# bereits gerundet.\n\n# unser Datensatz muss ein df sein, damit scale funktioniert\numwelt <- as.data.frame(umwelt)\n\n#  Variablen skalieren\n# Skalieren der Variablen, damit ihr Einfluss vergleichbar wird \n# (Problem verschiedene Skalen der Variablen (bspw. Temperatur in Grad Celsius, \n# Niederschlag in Millimeter und Sonnenscheindauer in Minuten)\numwelt <- umwelt |> \n  mutate(tre200jx_scaled = scale(tre200jx), \n         tre200nx_scaled = scale(tre200nx),\n         rre150j0_scaled = scale(rre150j0), \n         rre150n0_scaled = scale(rre150n0), \n         sremaxdv_scaled = scale(sremaxdv))\n```\n:::\n\n\n# Aufgabe 3: Korrelationen und Variablenselektion\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Korrelierende Variablen koennen das Modelergebnis verfaelschen. Daher muss vor der\n# Modelldefinition auf Korrelation getestet werden.\n\n# Erklaerende Variablen definieren\n# Hier wird die Korrelation zwischen den (nummerischen) erklaerenden Variablen berechnet\ncor <-  cor(umwelt[,12:16]) # in den [] waehle ich die skalierten Spalten.\n# Mit dem folgenden Code kann eine simple Korrelationsmatrix aufgebaut werden\n# hier kann auch die Schwelle für die Korrelation gesetzt werden, \n# 0.7 ist liberal / 0.5 konservativ\n# https://researchbasics.education.uconn.edu/r_critical_value_table/\ncor[abs(cor)<0.7] <-  0 #Setzt alle Werte kleiner 0.7 auf 0 (diese sind dann ok, alles groesser ist problematisch!)\ncor\n\n# Korrelationsmatrix erstellen\n# Zur Visualisierung kann ein einfacher Plot erstellt werden:\nchart.Correlation(umwelt[,12:16], histogram=TRUE, pch=19)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-5-1.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\n# ich schliesse die Temperatur bei Nacht in den Modellen aufgrund der Korelation aus, \n# da ich davon ausgehe, dass die Temperatur bei Tag das Besuchsaufkommen besser erklaert\n```\n:::\n\n\n# Aufgabe 4 (OPTIONAL): Automatische Variablenselektion\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Automatisierte Variablenselektion (achtung, RECHENINTENSIV)\n# fuehre die dredge-Funktion und ein Modelaveraging durch\n# Hier wird die Formel für die dredge-Funktion vorbereitet\nf <- Total ~ Wochentag + Ferien + Phase + Monat + \n  tre200jx_scaled + rre150j0_scaled + rre150n0_scaled + \n  sremaxdv_scaled\n# Jetzt kommt der Random-Factor hinzu und es wird eine Formel daraus gemacht\nf_dredge <- paste(c(f, \"+ (1|Jahr)\"), collapse = \" \") |>\n  as.formula()\n# Das Modell mit dieser Formel ausführen\nm <- glmer.nb(f_dredge, data = umwelt, na.action = \"na.fail\")\n# Das Modell in die dredge-Funktion einfügen (siehe auch ?dredge)\nall_m <- dredge(m)\n# suche das beste Modell\nprint(all_m)\n# Importance values der Variablen\n# hier wird die wichtigkeit der Variablen in den verschiedenen Modellen abgelesen\nMuMIn::sw(all_m)\n\n# Schliesslich wird ein Modelaverage durchgeführt\n# Schwellenwert für das delta-AIC = 2\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2)\nsummary(avgmodel)\n```\n:::\n\n\n# Aufgabe 5: Verteilung der abhängigen Variabel pruefen\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# pruefe zuerst nochmals, ob wir NA im df haben:\nsum(is.na(umwelt$Total))\n\nf1<-fitdist(umwelt$Total,\"norm\")  # Normalverteilung\nf1_1<-fitdist((umwelt$Total + 1),\"lnorm\")  # log-Normalvert (beachte, dass ich +1 rechne. \n# log muss positiv sein; allerdings kann man die\n# Verteilungen dann nicht mehr miteinander vergleichen). \nf2<-fitdist(umwelt$Total,\"pois\")  # Poisson\nf3<-fitdist(umwelt$Total,\"nbinom\")  # negativ binomial\nf4<-fitdist(umwelt$Total,\"exp\")  # exponentiell\n# f5<-fitdist(umwelt$Total,\"gamma\")  # gamma (berechnung mit meinen Daten nicht möglich)\nf6<-fitdist(umwelt$Total,\"logis\")  # logistisch\nf7<-fitdist(umwelt$Total,\"geom\")  # geometrisch\n# f8<-fitdist(umwelt$Total,\"weibull\")  # Weibull (berechnung mit meinen Daten nicht möglich)\n\ngofstat(list(f1,f2,f3,f4,f6,f7), \n        fitnames = c(\"Normalverteilung\", \"Poisson\",\n                     \"negativ binomial\",\"exponentiell\", \"logistisch\",\n                     \"geometrisch\"))\n\n# die 2 besten (gemaess Akaike's Information Criterion) als Plot + normalverteilt, \nplot.legend <- c(\"Normalverteilung\", \"exponentiell\", \"negativ binomial\")\n# vergleicht mehrere theoretische Verteilungen mit den empirischen Daten\ncdfcomp(list(f1, f4, f3), legendtext = plot.legend)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-7-1.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\n# --> Verteilung ist gemäss AICc exponentiell. negativ binomial ist auch nicht schlecht.\n# --> ich entscheide mich für diese beide und probiere mit beiden Modelle aus.\n```\n:::\n\n\n# Aufgabe 6: Multivariates Modell berechnen\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\n# Hinweise zu GLMM: https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html\n\n# Ich verwende hier die Funktion glmer aus der Bibliothek lme4. \n# Die Totale Besucheranzahl soll durch verschiedene Parameter erklaert werden. \n# Die verschiedenen Jahre sollen hierbei nicht beachtet werden, \n# sie wird als random Faktor bestimmt --> Wir betrachten jedes Jahr für sich und nicht\n# den allgemeinen Trend\n\n# Einfacher Start\n# Auch wenn wir gerade herausgefunden haben, dass die Verteilung negativ binomial ist,\n# berechne ich für den Vergleich zuerst ein einfaches Modell der Familie poisson.\nTages_Model <- glmer(Total ~ Wochentag + Ferien + Phase + Monat + \n                       tre200jx_scaled + rre150j0_scaled + rre150n0_scaled + \n                       sremaxdv_scaled +\n                       (1|Jahr), family = poisson, data = umwelt)\n\nsummary(Tages_Model)\n# Inspektionsplots\nplot(Tages_Model, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-1.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-2.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\n# pruefe auf Overdispersion\ndispersion_glmer(Tages_Model) #it shouldn't be over 1.4\n# wir gut erklaert das Modell?\nr.squaredGLMM(Tages_Model) \n# check for multicollinearity\n# https://rforpoliticalscience.com/2020/08/03/check-for-multicollinearity-with-the-car-package-in-r/\ncar::vif(Tages_Model) # VIF für beide predictors = 1, d.h. voneinander unabhängig (kritisch wird es ab einem Wert von >4-5)\n\n# Berechne ein negativ binomiales Modell\n# gemäss AICc die zweitbeste Verteilung\nTages_Model_nb <- glmer.nb(Total ~ Wochentag + Ferien + Phase + Monat + \n                             tre200jx_scaled + rre150j0_scaled + rre150n0_scaled + \n                             sremaxdv_scaled +\n                             (1|Jahr), data = umwelt)\n\nsummary(Tages_Model_nb)\nplot(Tages_Model_nb, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-3.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model_nb)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-4.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\ndispersion_glmer(Tages_Model_nb)\nr.squaredGLMM(Tages_Model_nb) \ncar::vif(Tages_Model_nb)\n\n# auf quadratischen Term testen (\"es gehen weniger Leute in den Wald, wenn es zu heiss ist\")\nTages_Model_nb_quad <- glmer.nb(Total ~ Wochentag + Ferien + Phase + Monat + \n                                  tre200jx_scaled + I(tre200jx_scaled^2) + rre150j0_scaled + rre150n0_scaled + \n                                  sremaxdv_scaled +\n                                  (1|Jahr), data = umwelt)\n\nsummary(Tages_Model_nb_quad)\nplot(Tages_Model_nb_quad, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-5.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model_nb_quad)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-6.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\ndispersion_glmer(Tages_Model_nb_quad)\nr.squaredGLMM(Tages_Model_nb_quad) \ncar::vif(Tages_Model_nb_quad)\n\n# Interaktion testen, da Ferien und / oder Wochentage einen Einfluss auf\n# die Besuchszahlen waehrend des Lockown haben koennen!\n# (Achtung: Rechenintensiv!)\n# Tages_Model_nb_int <- glmer.nb(Anzahl_Total ~  Wochentag  * Ferien + Phase +\n#                                  tre200jx_scaled + I(tre200jx_scaled^2) * \n#                                  rre150j0_scaled + sremaxdv_scaled +\n#                                  (1|KW) + (1|Jahr), data = umwelt)\n# \n# summary(Tages_Model_nb_int)\n# plot(Tages_Model_nb_int, type = c(\"p\", \"smooth\"))\n# qqmath(Tages_Model_nb_int)\n# dispersion_glmer(Tages_Model_nb_int)\n# r.squaredGLMM(Tages_Model_nb_int) \n\n\n# Vergleich der Modellguete mittels AICc\ncand.models<-list()\ncand.models[[1]] <- Tages_Model\ncand.models[[2]] <- Tages_Model_nb\ncand.models[[3]] <- Tages_Model_nb_quad\n\nModnames<-c(\"Tages_Model\",\"Tages_Model_nb\", \n            \"Tages_Model_nb_quad\")\naictab(cand.set=cand.models,modnames=Modnames)\n#K = Anzahl geschaetzter Parameter (2 Funktionsparameter und die Varianz)\n#Delta_AICc <2 = Statistisch gleichwertig\n#AICcWt =  Akaike weight in %\n\n# --> Ich entscheide mich bei diesen drei Modellen für das Tages_Model_nb_quad\n# Warum: statistisch das beste und ich denke die Quadratur macht Sinn!\n# zudem wissen wir gem. Test der Verteilungen, dass negativ binomial Sinn macht.\n# PROBLEM: alle drei Modelle erfüllen gem. der Modelldiagnostik die VOrausetzungen \n# nicht komplett.\n\n# Berechne ein Modell mit exponentieller Verteilung:\n# gemäss AICc der Verteilung die zweitbeste\n# https://stats.stackexchange.com/questions/240455/fitting-exponential-regression-model-by-mle\nTages_Model_exp <- glmer((Total+1) ~ Wochentag + Ferien + Phase + Monat + \n                           tre200jx_scaled + I(tre200jx_scaled^2) + rre150j0_scaled + rre150n0_scaled + \n                           sremaxdv_scaled + (1|Jahr), family = Gamma(link=\"log\"), data = umwelt)\n\nsummary(Tages_Model_exp, dispersion=1)\nplot(Tages_Model_exp, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-7.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model_exp)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-8.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\ndispersion_glmer(Tages_Model_exp) #it shouldn't be over 1.4\nr.squaredGLMM(Tages_Model_exp) \ncar::vif(Tages_Model_nb_quad)\n\n# --> Die zweitbeste Verteilung (exp) führt auch nicht dazu, dass die Modellvoraussetzungen besser\n# erfüllt werden\n\n\n# 4.5 Transformationen ####\n# Die Modellvoraussetzungen waren überall mehr oder weniger verletzt.\n# Das ist ein Problem, allerdings auch nicht ein so grosses.\n# (man sollte es aber trotzdem ernst nehmen)\n# Schielzeth et al. Robustness of linear mixed‐effects models to violations of distributional assumptions\n# https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13434\n# Lo and Andrews, To transform or not to transform: using generalized linear mixed models to analyse reaction time data\n# https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full\n\n# die Lösung ist nun, die Daten zu transformieren:\n# mehr unter: https://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/\n\n# berechne skewness coefficient \nlibrary(moments)\nskewness(umwelt$Total)\n# A positive value means the distribution is positively skewed (rechtsschief).\n# The most frequent values are low; tail is toward the high values (on the right-hand side)\n\n# log 10, da stark rechtsschief\nTages_Model_quad_Jahr_log10 <- lmer(log10(Total+1) ~ Wochentag + Ferien + Phase + Monat + \n                                      tre200jx_scaled + I(tre200jx_scaled^2) + rre150j0_scaled + rre150n0_scaled + \n                                      sremaxdv_scaled + (1|Jahr), data = umwelt)\nsummary(Tages_Model_quad_Jahr_log10)\nplot(Tages_Model_quad_Jahr_log10, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-9.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model_quad_Jahr_log10)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-10.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\ndispersion_glmer(Tages_Model_quad_Jahr_log10)\nr.squaredGLMM(Tages_Model_quad_Jahr_log10) \ncar::vif(Tages_Model_nb_quad)\n# lmer zeigt keine p-Werte, da diese schwer zu berechnen sind. Alternative Packages berechnen diese\n# anhand der Teststatistik. Achtung: die Werte sind wahrscheinlich nicht präzise!\n# https://stat.ethz.ch/pipermail/r-sig-mixed-models/2008q2/000904.html\ntab_model(Tages_Model_quad_Jahr_log10, transform = NULL, show.se = TRUE)\n\n\n# natural log, da stark rechtsschief\nTages_Model_quad_Jahr_ln <- lmer(log(Total+1) ~ Wochentag + Ferien + Phase + Monat + \n                                   tre200jx_scaled + I(tre200jx_scaled^2) + rre150j0_scaled + rre150n0_scaled + \n                                   sremaxdv_scaled + (1|Jahr), data = umwelt)\nsummary(Tages_Model_quad_Jahr_ln)\nplot(Tages_Model_quad_Jahr_ln, type = c(\"p\", \"smooth\"))\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-11.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nqqmath(Tages_Model_quad_Jahr_ln)\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-8-12.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\ndispersion_glmer(Tages_Model_quad_Jahr_ln)\nr.squaredGLMM(Tages_Model_quad_Jahr_ln) \ncar::vif(Tages_Model_nb_quad)\n\n# --> Die Modellvoraussetzungen sind nicht deutlich besser erfüllt jetzt wo wir Transformationen \n# benutzt haben. log10 und ln performen beide etwa gleich.\n\n# Zusatz: ACHTUNG - Ruecktransformierte Regressionskoeffizienten zu erlangen (fuer die Interpretation, das Plotten), \n# ist zudem nicht moeglich (Regressionskoeffizienten sind nur im transformierten Raum linear). \n# Ein ruecktransformierter Regressionskoeffiziente haette eine nicht-lineare Beziehung mit der \n# abhaengigen Variable.\n\n\n# 4.6 Exportiere die Modellresultate ####\n# (des besten Modells)\ntab_model(Tages_Model_nb_quad, transform = NULL, show.se = TRUE)\n# The marginal R squared values are those associated with your fixed effects, \n# the conditional ones are those of your fixed effects plus the random effects. \n# Usually we will be interested in the marginal effects.\n```\n:::\n\n\n\n# Aufgabe 7: Modellvisualisierung\n\n::: {.cell layout-align=\"left\"}\n\n```{.r .cell-code}\nrescale_plot_num <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  \n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title=\"\")\n  labels <- round(seq(floor(min(unscaled_var)), ceiling(max(unscaled_var)), length.out = num_breaks+1)*x_scaling, x_nk)\n  \n  custom_breaks <- seq(min(scaled_var), max(scaled_var), by = ((max(scaled_var)-min(scaled_var))/num_breaks))\n  custom_limits <- c(min(scaled_var), max(scaled_var))\n  \n  plot_id <- plot_id +\n    scale_x_continuous(breaks = custom_breaks, limits = custom_limits, labels = c(labels), labs(x=x_lab)) +\n    scale_y_continuous(labs(y=y_lab), limits = c(0,50)) +\n    theme_classic(base_size = 20)\n  \n  return(plot_id)\n}\n\n## Tagesmaximaltemperatur\ninput_df     <-  Tages_Model_nb_quad\ninput_term   <- \"tre200jx_scaled [all]\"\nunscaled_var <- umwelt$tre200jx\nscaled_var   <- umwelt$tre200jx_scaled\nnum_breaks   <- 10\nx_lab        <- \"Temperatur [°C]\"\ny_lab        <- \"Fussgänger:innen pro Tag\"\nx_scaling    <- 1 # in prozent\nx_nk         <- 0   # x round nachkommastellen    \n\n\np_temp <- rescale_plot_num(input_df, input_term, unscaled_var, scaled_var, num_breaks, \n                         x_lab, y_lab, x_scaling, x_nk)\np_temp\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-9-1.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"temp.png\", width=15, height=15, units=\"cm\", dpi=1000, \n       path = \"fallstudie_s/results/\") \n\n\n## Wochentag\n\nrescale_plot_fac <- function(input_df, input_term, unscaled_var, scaled_var, num_breaks, x_lab, y_lab, x_scaling, x_nk) {\n  \n  plot_id <- plot_model(input_df, type = \"pred\", terms = input_term, axis.title = \"\", title=\"\")\n\n  plot_id <- plot_id +\n    scale_y_continuous(labs(y=y_lab), limits = c(0,50)) +\n    theme_classic(base_size = 20)+\n    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))\n  \n  return(plot_id)\n}\n\ninput_df     <-  Tages_Model_nb_quad\ninput_term   <- \"Wochentag [all]\"\nunscaled_var <- umwelt$Wochentag\nscaled_var   <- umwelt$Wochentag\nnum_breaks   <- 10\nx_lab        <- \"Wochentag\"\ny_lab        <- \"Fussgänger:innen pro Tag\"\nx_scaling    <- 1 # in prozent\nx_nk         <- 0   # x round nachkommastellen    \n\n\np_wd <- rescale_plot_fac(input_df, input_term, unscaled_var, scaled_var, num_breaks, \n                              x_lab, y_lab, x_scaling, x_nk)\np_wd\n```\n\n::: {.cell-output-display}\n![](7_Multivariat_Loesung_files/figure-html/unnamed-chunk-9-2.png){fig-align='left' width=672}\n:::\n\n```{.r .cell-code}\nggsave(\"wd.png\", width=15, height=15, units=\"cm\", dpi=1000, \n       path = \"fallstudie_s/results/\") \n```\n:::\n",
    "supporting": [
      "7_Multivariat_Loesung_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}