{
  "hash": "cfd1e9cb5ebecbe54a205eb6d7a7d5ac",
  "result": {
    "markdown": "## 7. Übung\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\nNachdem die deskriptiven Resultate vorliegen, kann jetzt die Berechnung eines multivariaten Modells angegangen werden. Das Ziel ist es, den Zusammenhang zwischen der gesamten Anzahl Besucher:innen (Total) und verschiedenen erklärenden Variablen (Wetter, Ferien, Phase Covid, Wochentag, KW, Jahr) aufzuzeigen.\n\n### Aufgabe 1: Verbinden von Daten (Join)\n\nAktuell haben wir noch zwei einzelne Datensätze von Interesse:\n\n1) einen mit den täglichen Besuchszahlen von Besucher:innen mit den dazugehörigen Datumsinformationen (Datensatz \"depo_d\" - zu Tagen aggregierte Stunden) \n\n2) und einen mit den Wetterparametern (\"meteo\"). \n\n- Diese beiden Datensätze müssen miteinander verbunden werden. __Ziel__: Ein Datensatz mit den täglichen Zähldaten und Datumsinformationen angereichert mit Wetterdaten. Der neue Datensatz soll \" __umwelt__ \" heissen.\n\n- Sind durch das Zusammenführen NA's entstanden? Falls ja, müssen __alle__ für die weiteren Auswertungen ausgeschlossen werden.\n\n### Aufgabe 2: Convinience Variablen, Faktoren, Skalieren\n\nWir haben bereits verschiedene Convinience Variablen definiert. Nun brauchen wir noch neu die Ferienzeiten als Faktor.\n\n#### 2a) \n\n- Definiert mit if_else() alle Ferienzeiträume in euren df umwelt. WENN Ferien waren, DANN = 1, SONST = 0\n\n__Hinweis:__ etwas ganz ähnliches habt ihr unter Import/Vorverarbeitung bereits für die Covid-Phasen gemacht.\n\n#### 2b)\n\n- Macht aus den Ferien einen Faktor.\n\n- Auch das Jahr und die KW müssen als Faktor vorliegen.\n\nHinweis: Im Modell werden die Levels der Variablen (z.B. bei der Phase: Normal, Lockdown 1 und 2, Covid) alphabetisch geordnet und die Effektstärken der einzelnen Levels gegenüber dem ersten Level gerechnet. Das macht wenig Sinn, den in diesem Fall zeigt es uns die Effekte von Lockdown 1, Lockdown 2 und Normal gegenüber Covid an. \n\nBesser wäre aber Lockdown 1, Lockdown 2 und Covid __gegenüber Normal__.\n\nDas ändert man, indem ihr die Phase zu einem Faktor macht und die Levels entsprechend ändert (gut möglich, dass ihr das bereits so definiert habt).\n\n\n- Nachfolgende Schritte funktionieren nur, wenn __umwelt__ als data.frame vorliegt! Prüft das und ändert das, falls noch kein __data.frame__ (Hinweis: auch ein \"tibble\" funktioniert nicht, obwohl bei der Abfrage __is.data.frame()__ TRUE angegeben wird. Damit ihr beim scalen keine NaN Werte erhaltet, wendet ihr darum am besten in allen Fällen zuerst den Befehl __as.data.frame()__ an).\n\n- Unser Modell kann in der abhängigen Variabel nur mit Ganzzahlen (Integer) umgehen. Daher müssen Kommazahlen in Integer umgewandelt werden. Zum Glück haben wir das schon gemacht und uns bleibt nichts weiter zu tun. =)\n\n#### 2c) \n\nProblem: verschiedene Skalen der Variablen (z.B. Temperatur in Grad Celsius, Niederschlag in Millimeter und Sonnenscheindauer in %)\n\n- Lösung: Skalieren aller Variablen mit Masseinheiten gemäss unterstehendem Code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\numwelt <- umwelt %>% \n  mutate(tre200jx_scaled = scale(tre200jx)%>%\n  ...\n```\n:::\n\n\n### Aufgabe 3: Korrelationen und Variablenselektion\n\n#### 3a) \n\nKorrelierende Variablen können das Modellergebnis verfälschen. Daher muss vor der Modelldefinition auf Korrelation zwischen den Messwerten getestet werden. Welches sind die erklärenden Variablen, welches ist die Abhängige? (Ihr müsst nicht prüfen, ob die Voraussetzungen zur Berechnung von Korrelationen erfüllt sind)\n\n- Teste mittels folgendem Code auf eine Korrelation zwischen den Messwerten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor <-  cor(umwelt[,ERSTE SPALTE MIT ERKLAERENDEN MESSWERTEN : \n                     LETZTE SPALTE MIT ERKLAERENDEN MESSWERTEN)])\n```\n:::\n\n\n### 3b) \n\n- Korrelationsmatrix erstellen\n\nMit dem folgenden Code kann eine Korrelationsmatrix (mit den Messwerten) aufgebaut werden. Hier kann auch die Schwelle für die Korrelation gesetzt werden (0.7 ist liberal / 0.5 konservativ).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncor[abs(cor) < 0.7] <-  0 #Setzt alle Werte kleiner 0.7 auf 0\n```\n:::\n\n\nZur Visualisierung kann ein einfacher Plot erstellt werden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nchart.Correlation(umwelt[,ERSTE SPALTE MIT ERKLAERENDEN MESSWERTEN : \n                     LETZTE SPALTE MIT ERKLAERENDEN MESSWERTEN)], histogram=TRUE, pch=19)\n```\n:::\n\n\nWo kann eine kritische Korrelation beobachtet werden? Kann man es verantworten, trotzdem alle drei Wetterparameter in das Modell zu geben? \n\nFalls ja: warum? Falls nein: schliesst den betreffenden Parameter aus. Wenn ihr Parameter ausschliesst: welchen der beiden korrelierenden Parameter behaltet ihr im Modell?\n\n## Aufgabe 4 (OPTIONAL): Automatische Variablenselektion\n\nFühre die dredge-Funktion und ein Modelaveraging durch. Der Code dazu ist unten. \nWas passiert in der Funktion? Macht es Sinn, die Funktion auszuführen?\n\n__Hinweis:__ untenstehender Code ist rechenentensiv.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf <- Total ~ Wochentag + Ferien + Phase +\n  tre200jx_scaled + rre150j0_scaled + sremaxdv_scaled\n# Jetzt kommt der Random-Factor hinzu und es wird eine Formel daraus gemacht\nf_dredge <- paste(c(f, \"+ (1|KW)\", \"+ (1|Jahr)\"), collapse = \" \") %>% \n  as.formula()\n# Das Modell mit dieser Formel ausführen\nm <- glmer(f_dredge, data = umwelt, family = poisson, na.action = \"na.fail\")\n# Das Modell in die dredge-Funktion einfügen (siehe auch ?dredge)\nall_m <- dredge(m)\n# suche das beste Modell\nprint(all_m)\n# Importance values der Variablen \n# hier wird die wichtigkeit der Variablen in den verschiedenen Modellen abgelesen\nMuMIn::importance(all_m) \n\n# Schliesslich wird ein Modelaverage durchgeführt \n# Schwellenwert für das delta-AIC = 2\navgmodel <- model.avg(all_m, rank = \"AICc\", subset = delta < 2) \nsummary(avgmodel)\n```\n:::\n\n\n## Aufgabe 5: Verteilung der abhängigen Variabel pruefen\n\nDie Verteilung der abhängigen Variabel bestimmt generell, was für ein Modell geschrieben werden kann. Die Modelle gehen von einer gegebenen Verteilung aus. Wenn diese Annahme verletzt wird, kann es sein, dass das Modellergebnis nicht valide ist.\n\n- Folgender Codeblock zeigt, wie die Daten auf verschiedene Verteilungen passen.\n\n__Hinweis:__ es kann sein, dass nicht jede Verteilung geplottet werden kann, es erscheint eine Fehlermeldung. Das ist nicht weiter schlimm, die betreffende Verteilung kann gelöscht werden. Analog muss das auch im Befehl __gofstat()__ passieren.\n\n- Die besten drei Verteilungen (gemäss AIC) sollen zur Visualisierung geplottet werden. Dabei gilt, je besser die schwarze Punktlinie (eure Daten) auf die farbigen Linien (theoretische Verteilungen) passen, desto besser ist diese Verteilung geeignet.\n\n__Hinweis:__ CDF =  Cumulative distribution function; Wikipedia = \"Anschaulich entspricht dabei der Wert der Verteilungsfunktion an der Stelle x der Wahrscheinlichkeit, dass die zugehörige Zufallsvariable X einen Wert kleiner oder gleich x annimmt.\" \n\n\n::: {.cell}\n\n```{.r .cell-code}\nf1<-fitdist(umwelt$Anzahl_Total,\"norm\")  # Normalverteilung\nf1_1<-fitdist(umwelt$Anzahl_Total,\"lnorm\")  # log-Normalvert. \nf2<-fitdist(umwelt$Anzahl_Total,\"pois\")  # Poisson\nf3<-fitdist(umwelt$Anzahl_Total,\"nbinom\")  # negativ binomial\nf4<-fitdist(umwelt$Anzahl_Total,\"exp\")  # exponentiell\nf5<-fitdist(umwelt$Anzahl_Total,\"gamma\")  # gamma\nf6<-fitdist(umwelt$Anzahl_Total,\"logis\")  # logistisch\nf7<-fitdist(umwelt$Anzahl_Total,\"geom\")  # geometrisch\nf8<-fitdist(umwelt$Anzahl_Total,\"weibull\")  # Weibull\n\ngofstat(list(f1,f1_1,f2,f3,f4,f5,f6,f7,f8), \n        fitnames = c(\"Normalverteilung\", \"log-Normalverteilung\", \"Poisson\",\n                     \"negativ binomial\",\"exponentiell\",\"gamma\", \"logistisch\",\n                     \"geometrisch\",\"weibull\"))\n\n## die 4 besten (gemaess Akaike's Information Criterion) als Plot, \nplot.legend <- c(\"log norm\", \"weibull\", \"gamma \", \"negativ binomial\")\n## vergleicht mehrere theoretische Verteilungen mit den empirischen Daten\ncdfcomp(list(f1_1, f8, f5, f3), legendtext = plot.legend)\n```\n:::\n\n\nWie sind unsere Daten verteilt? Welche Modelle können wir anwenden?\n\n## Aufgabe 6: Multivariates Modell berechnen\n\nIch verwende die Funktion __glmer()__ aus der Bibliothek __lme4__. glmer ist neuer, schneller und zuverlässiger als vergleichbare Funktionen (diese Bibliothek wird auch in vielen wissenschaftlichen Papern im Feld Biologie / Wildtiermamagement zitiert).\n\nHinweise zu GLMM: https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html\n\n\n### 6a) \n\n__Hinweis:__ Auch wenn wir gerade herausgefunden haben, dass die Verteilung negativ binomial (in meinem Fall) ist, berechne ich für den Vergleich zuerst ein \"einfaches Modell\" der Familie poisson. Alternative Modelle rechnen wir in 6c.\n\n- Die Totale Besucheranzahl soll durch die Wetterparameter, den Wochentag, die Ferien sowie die Covid-Phasen erklärt werden (Datensatz \"umwelt\"). Die Saisonalität (KW und Jahr) soll hierbei nicht beachtet werden, sie werden als \"random factor\" bestimmt. \n\nFrage: Warum bestimmen wir KW und Jahr als random factor?\n\nFalls ihr der Meinung seid, KW und / oder Jahr sind keine \"guten\" random factor, dann nehmt sie nicht an random factor ins Modell sondern als erklärende Variable. Begründet das unbedingt in eurer Methodik.\n\nDie Modellformel lautet:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTages_Model <- glmer(ABHAENGIGE VARIABLE ~ ERKLAERENDE VARIABLE 1 + ERKLAERENDE VARIABLE 2 +\n                      ERKLAERENDE VARIABLE 3 + ERKLAERENDE VARIABLE 4 + \n                      ERKLAERENDE VARIABLE 5 + ERKLAERENDE VARIABLE 6 +\n                     (1|RANDOM FACTOR A)+ (1|RANDOM FACTOR B),\n                     family = poisson, data = DATENSATZ))\n\nsummary(Tages_Model) #Zeigt das Resultat des Modells\n```\n:::\n\n\nFrage: Was bedeutet \"family = poisson\"?\n\nLöst zuerst Aufgabe 6b bevor ihr alternative Modelle rechnet; das kommt in Aufgabe 6c!\n\n### 6b) Modelldiagnostik\n\n- Prüft optisch ob euer Modell valide ist.\n\n__Hinweis:__ glmer bringt einige eigene Funktionen mit, mit denen sich testen lässt, ob das Modell valide ist. Unten sind sie aufgeführt (--> analog zu den Funktionen aus der Vorlesung, aber halt für glmer).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Verteilung der Residuen (Varainzhomogenitaet)\nplot(Tages_Model, type = c(\"p\", \"smooth\"))\n## Pruefen auf Normalverteilung der Residuen\nqqmath(Tages_Model)\n\n## Overdispersion describes the observation that variation is higher than would be expected.\ndispersion_glmer(Tages_Model) #it shouldn't be over 1.4\n## zeige die erklaerte Varianz (je hoeher r2m ist, desto besser!)\nr.squaredGLMM(Tages_Model) \n```\n:::\n\n\nSind die Voraussetzungen des Modells erfuellt?\n\n### 6c) Alternative Modelle\n\nWir sind auf der Suche nach dem minimalen adäquaten Modell. Das ist ein iterativer Prozess. Wir schreiben ein Modell, prüfen ob die Voraussetzungen erfüllt sind und ob die abhängige Variable besser erklärt wird als im vorhergehenden. Und machen das nochmals und nochmals...\n\n  - Über __family =__ kann in der Funktion _glmer()__ einiges (aber leider nicht alles so einfach [z.B. negativ binomiale Modelle]) angepasst werden:\nhttps://stat.ethz.ch/R-manual/R-devel/library/stats/html/family.html\n- Auch über __link =__ kann man anpassen:\nhttps://stat.ethz.ch/R-manual/R-devel/library/stats/html/make.link.html\n\n- Unsere (meine) Daten sind negativ binomial verteilt. Daher sollte wir unbedingt ein solches Modell programmieren. --> Funktion __glmer.nb()__\n\n- Falls die Daten exponentiell Verteilt sind, hier der Link zu einem Blogeintrag dazu: \nhttps://stats.stackexchange.com/questions/240455/fitting-exponential-regression-model-by-mle\n\n- Hypothese: \"Es gehen weniger Leute in den Wald, wenn es zu heiss ist\" --> auf quadratischen Term Temperatur testen (Codeblock unten).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n...\ntre200jx_scaled + I(tre200jx_scaled^2) + \n  ...\n```\n:::\n\n\n- Könnte es zwischen einzelnen Variablen zu Interaktionen kommen, die plausible sind? (z. B.: Im Winter hat Niederschlag einen negativeren Effekt als im Sommer, wenn es heiss ist) --> Falls ja: testen!\n\n__Hinweis:__ Interaktionen berechnen ist sehr rechenintensiv. Auch die Interpretation der Resultate wird nicht unbedingt einfacher. Wenn ihr auf Interaktionen testet, dann geht \"langsam\" vor, probiert nicht zu viel auf einmal.\n\n- Wenn ihr verschiedene Modelle gerechnet habt, können diese über den AICc verglichen werden. Folgender Code kann dazu genutzt werden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Vergleich der Modellguete mittels AICc\ncand.models<-list()\ncand.models[[1]] <- Tages_Model\ncand.models[[2]] <- Tages_Model_nb\ncand.models[[3]] <- Tages_Model_nb_quad\n\nModnames<-c(\"Tages_Model\",\"Tages_Model_nb\", \n            \"Tages_Model_nb_quad\")\naictab(cand.set=cand.models,modnames=Modnames)\n##K = Anzahl geschaetzter Parameter (2 Funktionsparameter und die Varianz)\n##Delta_AICc <2 = Statistisch gleichwertig\n##AICcWt =  Akaike weight in %\n```\n:::\n\n\n### 6d) (OPTIONAL) Transformationen\n\nBei meinen Daten waren die Modellvoraussetzungen überall mehr oder weniger verletzt. Das ist ein Problem, allerdings auch nicht ein so grosses (man sollte es aber trotzdem ernst nehmen).\nMehr dazu unter:\n\nSchielzeth et al. Robustness of linear mixed‐effects models to violations of distributional assumptions\nhttps://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.13434\nLo and Andrews, To transform or not to transform: using generalized linear mixed models to analyse reaction time data\nhttps://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full\n\nFalls die Voraussetzungen stark verletzt werden, wäre eine Transformation angezeigt.\n\nMehr dazu unter:\n\nhttps://www.datanovia.com/en/lessons/transform-data-to-normal-distribution-in-r/\n\n\n- Berechne den skewness coefficient \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(moments)\nskewness(umwelt$Anzahl_Total)\n## A positive value means the distribution is positively skewed (rechtsschief).\n## The most frequent values are low; tail is toward the high values (on the right-hand side)\n```\n:::\n\n\n- Welche Transformation kann angewandt werden?\n\n- Was spricht gegen eine Transformation (auch im Hinblick zur Visualisierung und Interpretation)? Was spricht dafür?\n\n### 6c) Exportiere die Modellresultate (des besten Modells)\n\nModellresultate können mit __summary()__ angezeigt werden. Ich verwende aber lieber die Funktion __tab_model()__! Die Resultate werden gerundet und praktisch im separaten Fenster angezeigt. Von dort kann man sie via copy + paste ins (z.B.) Word bringen. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntab_model(MODELLNAME, transform = NULL, show.se = TRUE)\n## The marginal R squared values are those associated with your fixed effects, \n## the conditional ones are those of your fixed effects plus the random effects. \n## Usually we will be interested in the marginal effects.\n```\n:::\n\n\n\n## Aufgabe 7: Modellvisualisierung\n\n- Visualisiert die (signifikanten) Ergebnisse eures Modells. \n\nDas Resultat soll sich für kontinuierliche Variablen an untenstehendem Plot orientieren:\n\n\n::: {.cell}\n\n:::\n\n\nFür diskrete Variablen haltet ihr euch bitte an diesen Plot:\n\n\n::: {.cell}\n\n:::\n\n\nEinige Codeblocks, die euch dabei helfen können:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- plot_model(NAME_DES_BESTEN_MODELLS, # hier sagen wir, aus welchem Modell geplottet werden soll\n                \n                # Wir moechten nicht nur die tatsaechlichen Werte geplottet, sondern \n                # \"Vorhersagen\" / predictions (fuer jeden Wert auf der x-Achse soll es auch einen\n                # auf der y-Achse geben)\n                type = \"pred\", \n                \n                # jetzt nennen wir den Term aus dem Modell:\n                # [all] = Unser Modell enthaellt polynomial oder cubic / quadratic Terme. \n                # mit [all] tragen wir dem Rechnung und zeichnen \"smooth\" plots\n                terms = \"tre200jx_scaled [all]\", \n                \n                # und schliesslich setzen wir die Achsentitel\n                title = \"\", axis.title = c(\"Tagesmaximaltemperatur [°C]\", \n                                           \"Fussgaenger:innen pro Tag [log]\"))\n\n## Vorbereitungen zum Hinzufuegen der Achsenbeschriftung (Aktuell sehen wir noch die skalierten Werte). \n## Nun sollen aber die unskalierten Werte gezeigt werden.\nlabels <- round(seq(floor(min(umwelt$tre200jx)), ceiling(max(umwelt$tre200jx)),\n                    \n                    # length.out = ___ --> Anpassen gemaess der Anzahl zu sehender breaks auf dem Plot\n                    length.out = 5), 0) \n## Schliesslich fuegen wir die Achsenbeschriftung hinzu.\n(Tempplot <- t + \n    \n    # fuege die x- Achsenbeschriftung hinzu.\n    # breaks = c() --> Anpassen gemaess der zu sehender breaks auf dem Plot\n    scale_x_continuous(breaks = c(-2,-1,0,1,2), \n                       labels = c(labels))+\n    \n    # fuege die y- Achsenbeschriftung hinzu. Hier transformieren wir die Werte zurueck\n    # Hinweis: falls ihr keine Transformation gemacht habt, muessen die y-Werte auch nicht \n    # zuruecktransformiert werden.\n    scale_y_continuous(breaks = c(0,0.5,1,1.5,2),\n                       labels = round(c(10^0, 10^0.5, 10^1, 10^1.5, 10^2),0),\n                       limits = c(0, 2))+ \n    theme_classic(base_size = 15))\n\n## Exportiere das Resultat\nggsave(\"temp.png\", width=15, height=15, units=\"cm\", dpi=1000, \n       path = \"fallstudien/_R_analysis/results/\") \n```\n:::\n\n\n__Hinweis:__ damit unsere Plots verglichen werden können, sollen sie alle dieselbe Skalierung (limits) auf der y-Achse haben. Das wird erreicht, indem man bei jedem Plot die __limits__ in __scale_y_continuous()__ gleichsetzt.\n\n#w# Abschluss\n\nNun habt ihr verschiedenste Ergebnisse vorliegen. In einem wissenschaftlichen Bericht sollen aber niemals alle Ergebnisse abgebildet werden. Eine Faustregel besagt, dass nur signifikante Ergebnisse visualisiert werden. Entscheidet euch daher, was ihr in eurem Bericht abbilden wollt und was lediglich besprochen werden soll.",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}